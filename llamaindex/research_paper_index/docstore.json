{"docstore/data": {"6485898a-5c5f-4be4-b369-3d6d7cf0c8a0": {"__data__": {"id_": "6485898a-5c5f-4be4-b369-3d6d7cf0c8a0", "embedding": null, "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ca2a1d0-3497-481b-bce2-e039f68cffd2", "node_type": "4", "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d163aa9d8163de05ef79843f33681c45cfa1ff95eb3919066be264b1a5e797e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "869df95b-1f65-4331-a246-91ca55433845", "node_type": "1", "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "9ebccb17124cb43a671808672bca1d209e208d3cfc35aaa269725adf940a213e", "class_name": "RelatedNodeInfo"}}, "hash": "47c8394548352ef46e14ae0026c5591a46028b486caa7a844463eab07490d474", "text": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models\nMaciej Besta1*, Nils Blach1*, Ales Kubicek1, Robert Gerstenberger1,\nLukas Gianinazzi1, Joanna Gajda2, Tomasz Lehmann2, Micha\u0142 Podstawski3,\nHubert Niewiadomski2, Piotr Nyczyk2, Torsten Hoefler1\n1ETH Zurich,2Cledar,3Warsaw University of Technology\nbestam@inf.ethz.ch, nils.blach@inf.ethz.ch, htor@inf.ethz.ch\nAbstract\nWe introduce Graph of Thoughts (GoT): a framework that\nadvances prompting capabilities in large language models\n(LLMs) beyond those offered by paradigms such as Chain-of-\nThought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information gen-\nerated by an LLM as an arbitrary graph , where units of infor-\nmation (\u201cLLM thoughts\u201d) are vertices, and edges correspond\nto dependencies between these vertices. This approach en-\nables combining arbitrary LLM thoughts into synergistic out-\ncomes, distilling the essence of whole networks of thoughts,\nor enhancing thoughts using feedback loops. We illustrate\nthat GoT offers advantages over state of the art on different\ntasks, for example increasing the quality of sorting by 62%\nover ToT, while simultaneously reducing costs by >31%.\nWe ensure that GoT is extensible with new thought transfor-\nmations and thus can be used to spearhead new prompting\nschemes. This work brings the LLM reasoning closer to hu-\nman thinking or brain mechanisms such as recurrence, both\nof which form complex networks.\nWebsite & code: https://github.com/spcl/graph-of-thoughts\n1 Introduction\nLarge language models (LLMs) are taking over the world\nof AI. Recent years saw a rapid development of models pri-\nmarily based on the decoder-only Transformer variant [64],\nsuch as GPT [52, 51, 14, 13], PaLM [19], or LLaMA [62].\nPrompt engineering is a resource-efficient approach for\nsolving different LLM tasks. In brief, one includes the task\ndescription within the input sent to an LLM. If this descrip-\ntion is appropriately formulated, the LLM solves the task\nusing its autoregressive token-based mechanism for gener-\nating text. Such prompts may contain example tasks with\nsolutions (few-shot prompting, also referred to as in-context\nlearning (ICL)), or even no example tasks at all (zero-shot\nprompting). Recent years shown that this mechanism can be\nused to solve a broad set of tasks that involve mathematical,\ncommonsense, or symbolic reasoning.\nChain-of-Thought (CoT) [70] is an approach for prompt-\ning, in which one includes the intermediate steps of rea-\nsoning within the prompt (intermediate \u201cthoughts\u201d), besides\nthe task input/output. CoT was shown to significantly im-\nprove the capability of LLMs to solve problems without re-\nsorting to any model updates. One major improvement over\n*Equal contributionCoT, Self-Consistency with CoT (CoT-SC) [66], is a scheme\nwhere multiple CoTs are generated, and then the best one is\nselected as the outcome. More recently, CoT and CoT-SC\nwere extended with Tree of Thoughts (ToT) [43, 76, 74],\nwhich models the LLM reasoning process with a tree. This\nfacilitates using different paths of thoughts, and offers novel\ncapabilities such as backtracking from non-promising out-\ncomes. Unfortunately, the ToT approaches still fundamen-\ntally limit the reasoning abilities within a prompt by impos-\ning the rigid tree structure on the thought process.\nIn this work, we argue that fundamentally more power-\nful prompting can be achieved by enabling LLM thoughts to\nform an arbitrary graph structure. This is motivated by nu-\nmerous phenomena such as human reasoning, brain struc-\nture, or algorithmic execution. When working on a novel\nidea, a human would not only follow a chain of thoughts\n(as in CoT) or try different separate ones (as in ToT), but\nwould actually form a more complex network of thoughts.\nFor example, one could explore a certain chain of reason-\ning, backtrack and start a new one, then realize that a cer-\ntain idea from the previous chain could be combined with\nthe currently explored one, and merge them both into a new\nsolution, taking advantage of their strengths and eliminat-\ning their weaknesses.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "869df95b-1f65-4331-a246-91ca55433845": {"__data__": {"id_": "869df95b-1f65-4331-a246-91ca55433845", "embedding": null, "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ca2a1d0-3497-481b-bce2-e039f68cffd2", "node_type": "4", "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d163aa9d8163de05ef79843f33681c45cfa1ff95eb3919066be264b1a5e797e9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6485898a-5c5f-4be4-b369-3d6d7cf0c8a0", "node_type": "1", "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "47c8394548352ef46e14ae0026c5591a46028b486caa7a844463eab07490d474", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "564b697d-6daf-42ed-863b-b70d68409e88", "node_type": "1", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "1a9839901b431bb42d48d8158ffc3dc01e6c115b3350edab5166b6ba10b196cd", "class_name": "RelatedNodeInfo"}}, "hash": "9ebccb17124cb43a671808672bca1d209e208d3cfc35aaa269725adf940a213e", "text": "In this work, we argue that fundamentally more power-\nful prompting can be achieved by enabling LLM thoughts to\nform an arbitrary graph structure. This is motivated by nu-\nmerous phenomena such as human reasoning, brain struc-\nture, or algorithmic execution. When working on a novel\nidea, a human would not only follow a chain of thoughts\n(as in CoT) or try different separate ones (as in ToT), but\nwould actually form a more complex network of thoughts.\nFor example, one could explore a certain chain of reason-\ning, backtrack and start a new one, then realize that a cer-\ntain idea from the previous chain could be combined with\nthe currently explored one, and merge them both into a new\nsolution, taking advantage of their strengths and eliminat-\ning their weaknesses. Similarly, brains form complex net-\nworks, with graph-like patterns such as recurrence [28]. Ex-\necuting algorithms also expose networked patterns, often\nrepresented by Directed Acyclic Graphs. The correspond-\ninggraph-enabled transformations bring a promise of more\npowerful prompting when applied to LLM thoughts, but they\nare not naturally expressible with CoT or ToT.\nWe observe that these (and many other) thought trans-\nformations can be naturally enabled when modeling a rea-\nsoning process of an LLM as a graph . For this, we pro-\npose Graph of Thoughts (GoT), an approach that en-\nhances LLMs\u2019 capabilities through networked reasoning\n(contribution #1 ). In GoT, an LLM thought is modeled\nas a vertex, while an edge is a dependency between such\nthoughts. Using GoT, one can aggregate arbitrary thoughts\nby constructing vertices that have more than one incom-\ning edge. Overall, the graph abstraction harnessed by GoT\nseamlessly generalizes CoT and ToT to more complex\nthought patterns, without resorting to any model updates .\nYet, putting GoT to practice requires solving several de-\nsign challenges. For example, what is the best graph struc-\nture for different tasks? How to best aggregate thoughts to\nmaximize accuracy and minimize cost? To answer these andarXiv:2308.09687v2  [cs.CL]  21 Aug 2023", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "564b697d-6daf-42ed-863b-b70d68409e88": {"__data__": {"id_": "564b697d-6daf-42ed-863b-b70d68409e88", "embedding": null, "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef5bc24e-11ab-42d6-b1c5-4db1ff1239cc", "node_type": "4", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d6011c769c16871f5bdfc41d2a90a12402a1fdca13a978b9f2f2213e5827c52c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "869df95b-1f65-4331-a246-91ca55433845", "node_type": "1", "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "9ebccb17124cb43a671808672bca1d209e208d3cfc35aaa269725adf940a213e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514", "node_type": "1", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "3a1000dda82df60ab1f5d58e1ffb30d9b639763048f318ac72a217581a0a169a", "class_name": "RelatedNodeInfo"}}, "hash": "1a9839901b431bb42d48d8158ffc3dc01e6c115b3350edab5166b6ba10b196cd", "text": "many other questions, we carefully design a modular archi-\ntecture for implementing GoT ( contribution #2 ), coming\nwith two design highlights. First, we enable a fine-grained\ncontrol over individual thoughts . This enables us to fully\ncontrol the ongoing conversation with the LLM, and apply\nadvanced thought transformations, such as combining most\npromising thoughts from the ongoing reasoning into a new\none. Second, we ensure that our architecture can be seam-\nlessly extended with novel thought transformations, patterns\nof reasoning (i.e., graphs of thoughts), and LLM models.\nThis enables rapid prototyping of novel prompting ideas us-\ning GoT, while experimenting with different models such as\nGPT-3.5, GPT-4, or Llama-2 [63].\nWe illustrate several use cases for GoT (sorting, keyword\ncounting for summaries, set operations, document merging)\nand we detail how to implement them using the graph-based\nparadigm ( contribution #3 ). We evaluate GoT and show its\nadvantages over the state of the art ( contribution #4 ). Over-\nall, we observe that GoT is particularly well-suited for tasks\nthat can be naturally decomposed into smaller subtasks that\nare solved individually and then merged for a final solution.\nHere, GoT outperforms other schemes, for example improv-\ning upon CoT and ToT by, respectively, \u224870% and \u224862%,\nin terms of the quality of sorting, while simultaneously re-\nducing costs by >31% over ToT.\nWe qualitatively compare GoT to other prompting\nschemes in Table 1. GoT is the only one to enable arbitrary\ngraph-based thought transformations within a prompt, such\nas aggregation, embracing all previously proposed schemes.\nScheme Sc? Mc? Tr? Ag?\nChain-of-Thought (CoT) [70] /reve /reve /reve\nSelf-Consistency with CoT [66] /reve /reve\nThought decomposition [74] /reve\nTree-of-Thought (ToT) [43] /reve\nTree of Thoughts (ToT) [76] /reve\nGraph of Thoughts (GoT) \nTable 1: Comparison of prompting schemes, with re-\nspect to the supported transformations of thoughts. \u201cSc?\u201d :\nsingle chain of thoughts? \u201cMc?\u201d : multiple chains of\nthoughts? \u201cTr?\u201d : tree of thoughts? \u201cAg?\u201d : arbitrary graph\nof thoughts? \u201c \u201d: full support, \u201c \u201d: partial support, \u201c /reve\u201d:\nno support. Note that we do not include a recent scheme\ncalled Graph-of-Thought [78] because it is not a prompting\nscheme. While its name suggests close connections to ToT\nand CoT, as a fine-tuning scheme, it resorts to model up-\ndates, and is thus outside the focus of this work.\nFinally, we propose a new metric for evaluating a prompt-\ning strategy, the volume of a thought (contribution #5 ).\nWith this metric, we aim to understand better the differences\nbetween prompting schemes. For a given thought v, the vol-\nume of visthe number of LLM thoughts, from which one\ncan reach vusing directed edges . Intuitively, these are all\nthe LLM thoughts that have had the potential to contribute\ntov. We show that GoT, by incorporating thought transfor-\nmations such as aggregation, enables thoughts to have fun-\ndamentally larger volumes than other schemes.2 Background & Notation\nWe first outline background concepts and notation.\n2.1 Language Models & In-Context Learning\nTheconversation with the LLM consists of user messages\n(prompts ) and LLM replies ( thoughts ). We follow the estab-\nlished notation [76] and we denote a pre-trained language\nmodel (LM) with parameters \u03b8asp\u03b8. Lowercase letters such\nasx, y, z, ... indicate LLM thoughts. We purposefully do not\nprescribe what is a single \u201cthought\u201d, and instead make it use-\ncase specific. Hence, a single thought can be a paragraph\n(e.g., in article summary), a document (e.g., in document\ngeneration), a block of code (e.g., in code debugging or op-\ntimization), and so on.\nWe next describe specific prompting approaches .\nInput-Output (IO) The Input-Output (IO) prompting is a\nstraightforward approach, in which we use an LLM to turn\nan input sequence xinto the output ydirectly , without any\nintermediate thoughts.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514": {"__data__": {"id_": "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514", "embedding": null, "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef5bc24e-11ab-42d6-b1c5-4db1ff1239cc", "node_type": "4", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d6011c769c16871f5bdfc41d2a90a12402a1fdca13a978b9f2f2213e5827c52c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "564b697d-6daf-42ed-863b-b70d68409e88", "node_type": "1", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "1a9839901b431bb42d48d8158ffc3dc01e6c115b3350edab5166b6ba10b196cd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0148c831-ddb5-41c4-b1b9-5a29081f6a88", "node_type": "1", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "7d454f0ae7250b156221c382d2863a4651211579410b4630b6bb762183e49be1", "class_name": "RelatedNodeInfo"}}, "hash": "3a1000dda82df60ab1f5d58e1ffb30d9b639763048f318ac72a217581a0a169a", "text": "We follow the estab-\nlished notation [76] and we denote a pre-trained language\nmodel (LM) with parameters \u03b8asp\u03b8. Lowercase letters such\nasx, y, z, ... indicate LLM thoughts. We purposefully do not\nprescribe what is a single \u201cthought\u201d, and instead make it use-\ncase specific. Hence, a single thought can be a paragraph\n(e.g., in article summary), a document (e.g., in document\ngeneration), a block of code (e.g., in code debugging or op-\ntimization), and so on.\nWe next describe specific prompting approaches .\nInput-Output (IO) The Input-Output (IO) prompting is a\nstraightforward approach, in which we use an LLM to turn\nan input sequence xinto the output ydirectly , without any\nintermediate thoughts.\nChain-of-Thought (CoT) Second, in Chain-of-Thought\n(CoT), one introduces intermediate thoughts a1, a2, ...be-\ntween xandy. This strategy was shown to significantly en-\nhance various LM tasks over the plain IO baseline, such as\nmathematical puzzles [70] or general mathematical reason-\ning [24].\nMultiple CoTs Third, one can generalize CoT into multi-\nple CoTs by generating several (independent) kCoTs, and\nreturning the one with the best output (according to some\nprescribed scoring metric). It was introduced by Wang et\nal. in the scheme called Self-Consistency with CoT (CoT-\nSC) [66]. This approach enhances CoT because it offers an\nopportunity to explore different reasoning paths. However,\nit does not offer \u201clocal exploration\u201d within a path, such as\nbacktracking.\nTree of Thoughts (ToT) Finally, the Tree of Thoughtd\n(ToT) scheme was introduced independently by Yao [76]\nand Long [43] (where it is referred to as Tree-of-Thought);\nit was used implicitly to a certain degree by other schemes\nsuch as thought decomposition [74]. It enhances CoT-SC by\nmodeling the process or reasoning as a treeof thoughts. A\nsingle tree node represents a partial solution. Based on a\ngiven node, the thought generator constructs a given number\nkof new nodes. Then, the state evaluator generates scores\nfor each such new node. Depending on the use case, the eval-\nuation could be conducted using an LLM itself, or it can har-\nness human scores. Finally, the schedule of extending the\ntree is dictated by the utilized search algorithm (for example\nBFS or DFS).\n3 The GoT Framework\nWe now detail the GoT framework. We present it in Figure 1,\nand compare it to other prompting strategies.\nFormally, GoT can be modeled as a tuple (G,T,E,R),\nwhere Gis the \u201cLLM reasoning process\u201d (i.e., all the LLM\nthoughts within the context, with their relationships), Tare", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0148c831-ddb5-41c4-b1b9-5a29081f6a88": {"__data__": {"id_": "0148c831-ddb5-41c4-b1b9-5a29081f6a88", "embedding": null, "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79786b26-060e-4428-85c2-d57843c47428", "node_type": "4", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "4acd09b9c369a1e2156e0e615106e5d846da0a206d6a1eca4ccac7cb2b9be65b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514", "node_type": "1", "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "3a1000dda82df60ab1f5d58e1ffb30d9b639763048f318ac72a217581a0a169a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb975f7b-b67e-4b6f-bdcb-cf417891ac90", "node_type": "1", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "17f03eecf8c35c928d8bb12f9f22c162f36d339a589ea60ed25aae61c0b3ea5d", "class_name": "RelatedNodeInfo"}}, "hash": "7d454f0ae7250b156221c382d2863a4651211579410b4630b6bb762183e49be1", "text": "Input\nOutputInput\nOutput OutputThoughts:\nUnscored\nNegative\nscore OutputInput\nOutput[This work]\nInput\nPositive\nscore\nDependencies\nbetween thoughts\nAbandon thought\nBacktrackBasic Input-\nOutput (IO)\nLegendMultiple CoTs (CoT-SC) Chain-of-\n-Thought\n(CoT)Tree of Thoughts (ToT) Graph of Thoughts (GoT)\nKey novelty:\nIntermediate\nLLM thoughts\nwithin a chainBranching out\nfrom a chain\nSelecting\na chain with\nthe best scoreAbandon a chain\nKey novelty\n(beyond CoT):\nHarnessing multiple\nindependent chains\nof thoughtsKey novelty\n(beyond CoT-SC):\nGenerating several\nnew thoughts based\non a given arbitrary\nthought, exploring\nit further, and possibly\nbacktracking from itKey novelty (beyond ToT):\nArbitrary graph-based thought\ntransformations (aggregating \nthoughts into a new one, \nlooping over a thought to \nrefine it)BacktrackingRefining\nAggregating\nthoughtsBacktracking\nfrom a chain\nIntermediate\nthoughts are\nalso scored\nAggregating\nchainsInputFigure 1: Comparison of Graph of Thoughts (GoT) to other prompting strategies.\nthe potential thought transformations, Eis an evaluator func-\ntion used to obtain scores of thoughts, and Ris a ranking\nfunction used to select most relevant thoughts.\n3.1 Reasoning Process\nWe model the reasoning process as a directed graph G=\n(V, E);Vis a set of vertices and E\u2286V\u00d7Vis a set of\nedges. Gis directed and thus the edges are a subset of or-\ndered vertex pairs E\u2286V\u00d7V. A vertex contains a solution\nto a problem at-hand (be it an initial, intermediate, or a fi-\nnal one). The concrete form of such a thought depends on\na use case; it could be a paragraph (in writing tasks) or a\nsequence of numbers (in sorting). A directed edge (t1, t2)\nindicates that thought t2has been constructed using t1as\n\u201cdirect input\u201d, i.e., by explicitly instructing the LLM to use\nt1for generating t2.\nIn certain use cases, graph nodes belong to different\nclasses . For example, in writing tasks, some vertices model\nplans of writing a paragraph , while other vertices model the\nactual paragraphs of text . In such cases, GoT embraces a\nheterogeneous graph G= (V, E, c )to model the LLM rea-\nsoning, where cmaps vertices Vinto their respective classes\nC(in the above case, it would be C={plan, par }). Hence,\nany vertex vcan model different aspects of reasoning.\nWe associate Gwith the LLM reasoning process. To ad-\nvance this process, one applies thought transformations to\nG. An example such transformation is to merge best-scoring\n(so far) thoughts into a new one. Another example is to loop\nover a thought, in order to enhance it. Note that these trans-\nformations strictly extend the set of transformations avail-\nable in the CoT, CoT-SC, or ToT.\n3.2 Transformations of Thoughts\nGoT enables novel transformations of thoughts thanks to\nthe graph-based model for reasoning. We refer to them as\ngraph-enabled transformations . For example, in writing,\none could combine several input articles into one coherent\nsummary. In sorting, one could merge several sorted subar-\n...Graph theory view Example sorting task Example writing taskAggregation Generation...\n1 2 7 8 1 1 4 5 2 3 6 7\n1 1 1 2 2 3 4 5 6 7 7 8...\nArticle\n1Article\n2Article\n3\nKeyword\nsummary\nA vertex models\na thought. An edge\nmodels dependency... ...Merging sorted subarrays\ninto a sorted array of numbers\nSplitting an unsorted array into\nsubarrays, for subsequent sortingCombining articles into\na coherent summary...\nKeyword\nsummary 1Keyword\nsummary 21 4 6 2 4 2 4 9 8 7 5 4\n1 4 6 2    4 2 4 9    8 7 5 4Article\n1\nGenerating summaries from\nan article, to maximize qualityFigure 2: Examples of aggregation and generation thought\ntransformations.\nrays of numbers into a final sorted array. We illustrate exam-\nples of aggregation and generation in Figure 2.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb975f7b-b67e-4b6f-bdcb-cf417891ac90": {"__data__": {"id_": "eb975f7b-b67e-4b6f-bdcb-cf417891ac90", "embedding": null, "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79786b26-060e-4428-85c2-d57843c47428", "node_type": "4", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "4acd09b9c369a1e2156e0e615106e5d846da0a206d6a1eca4ccac7cb2b9be65b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0148c831-ddb5-41c4-b1b9-5a29081f6a88", "node_type": "1", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "7d454f0ae7250b156221c382d2863a4651211579410b4630b6bb762183e49be1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f6ff5d4-dab4-44bf-8f45-5a217f8163ef", "node_type": "1", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "54f64124212052b57d24fa878478f22583e32f8e1310780fa657e3cd9b3bc111", "class_name": "RelatedNodeInfo"}}, "hash": "17f03eecf8c35c928d8bb12f9f22c162f36d339a589ea60ed25aae61c0b3ea5d", "text": "An edge\nmodels dependency... ...Merging sorted subarrays\ninto a sorted array of numbers\nSplitting an unsorted array into\nsubarrays, for subsequent sortingCombining articles into\na coherent summary...\nKeyword\nsummary 1Keyword\nsummary 21 4 6 2 4 2 4 9 8 7 5 4\n1 4 6 2    4 2 4 9    8 7 5 4Article\n1\nGenerating summaries from\nan article, to maximize qualityFigure 2: Examples of aggregation and generation thought\ntransformations.\nrays of numbers into a final sorted array. We illustrate exam-\nples of aggregation and generation in Figure 2.\nFormally, each such transformation can be modeled as\nT(G, p\u03b8)where G= (V, E)is the graph reflecting the\ncurrent state of the reasoning, and p\u03b8is the used LLM. T\nmodifies Gusually by adding new vertices and their incom-\ning edges. We have G\u2032=T(G, p\u03b8) = ( V\u2032, E\u2032), where\nV\u2032= (V\u222aV+)\\V\u2212andE\u2032= (E\u222aE+)\\E\u2212.V+\nandE+are new vertices and edges inserted into Gto model\nthe new thoughts and their dependencies, respectively. To\nmaximize the expressiveness of GoT \u2013 we also enable the\nuser to explicitly remove thoughts, by specifying the corre-\nsponding vertices and edges to be removed ( V\u2212andE\u2212, re-\nspectively). Here, it is the user\u2019s responsibility to ensure that\nthe sets V+, E+, V\u2212,andE\u2212come with consistent trans-\nformations (i.e., for example, that the user does not attempt\nto remove a vertex that does not exist). This enables seam-\nless incorporation of schemes where, in order to save space\nwithin the context, one can remove parts of reasoning that\ndo not promise improvements.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f6ff5d4-dab4-44bf-8f45-5a217f8163ef": {"__data__": {"id_": "4f6ff5d4-dab4-44bf-8f45-5a217f8163ef", "embedding": null, "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db78872b-b53c-4868-a04e-1d03e3198e42", "node_type": "4", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "b0343980c9b13144906459072f9901f5615e2eb3986fa45e772699042ef2dec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb975f7b-b67e-4b6f-bdcb-cf417891ac90", "node_type": "1", "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "17f03eecf8c35c928d8bb12f9f22c162f36d339a589ea60ed25aae61c0b3ea5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a581b211-3654-4628-81a1-1ecf1d4827a6", "node_type": "1", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d57f23aa30c5accfee0eb2a082b5c7eff9e75257b6101790f6b6e283c75e7f64", "class_name": "RelatedNodeInfo"}}, "hash": "54f64124212052b57d24fa878478f22583e32f8e1310780fa657e3cd9b3bc111", "text": "The specific form of Tand how it impacts Gdepends on\na specific transformation. We first detail the primary graph-\nenabled thought transformations, and then proceed to de-\nscribe how GoT embraces the transformations from the ear-\nlier schemes. Unless stated otherwise, V\u2212=E\u2212=\u2205.\nAggregation Transformations First, with GoT, one can\naggregate arbitrary thoughts into new ones, to combine\nand reinforce the advantages of these thoughts, while elim-\ninating their disadvantages. In the basic form, in which\nonly one new vertex is created, V+={v+}andE+=\n{(v1, v+), ...,(vk, v+)}, where v1, ..., v kare the merged k\nthoughts. More generally, this enables aggregating reason-\ning paths , i.e., longer chains of thoughts, beyond just indi-\nvidual thoughts. With the graph model, is it simply achieved\nby adding outgoing edges from the vertices v1, ..., v kmod-\neling final thoughts in several chains, into a single thought\nv+combining these chains.\nRefining Transformations Another thought transforma-\ntion is the refining of a current thought vby modifying its\ncontent: V+={}andE+={(v, v)}. This loop in the\ngraph indicates an iterated thought with the same connec-\ntions as the original thought.\nGeneration Transformations Finally, one can generate\none or more new thoughts based on an existing single\nthought v. This class embraces analogous reasoning steps\nfrom earlier schemes, such as ToT or CoT-SC. Formally, we\nhaveV+={v+\n1, ..., v+\nk}andE+={(v, v+\n1), ...,(v, v+\nk)}.\n3.3 Scoring & Ranking Thoughts\nThoughts are scored to understand whether the current solu-\ntion is good enough. A score is modeled as a general func-\ntionE(v, G, p \u03b8), where vis a thought to be evaluated. We\nuse the state of the whole reasoning process ( G) inEfor\nmaximum generality, because \u2013 for example \u2013 in some eval-\nuation scenarios, scores may be relative to other thoughts.\nGoT can also rank thoughts. We model this with a func-\ntionR(G, p\u03b8, h)where hspecifies the number of highest-\nranking thoughts in Gto be returned by R. While the spe-\ncific form of Rdepends on a use case, we most often use a\nsimple yet effective strategy where hthoughts with highest\nscores are returned, i.e., v1, ..., v h=R(G, p\u03b8, h).\nSpecific forms of EandRdepend on a use case. We dis-\ncuss the details in Section 5. For example, the score (or rank)\nfor sorting corresponds to the count of elements correctly\nsorted (or incorrectly, when obtaining the error as a score).\n4 System Architecture & Extensibility\nThe GoT architecture consists of a set of interacting mod-\nules, see Figure 3 (the blue part). These modules are the\nPrompter (prepares the messages for the LLM), the Parser\n(extracts information from LLMs\u2019 replies), the Scoring\nmodule (verifies and scores the LLM replies), and the Con-\ntroller (coordinates the entire reasoning process, and decides\non how to progress it). The Controller contains two further\nimportant elements: the Graph of Operations (GoO) and the\nGraph Reasoning State (GRS). GoO is a static structure thatspecifies the graph decomposition of a given task , i.e., it pre-\nscribes transformations to be applied to LLM thoughts, to-\ngether with their order & dependencies. GRS is a dynamic\nstructure that maintains the state of the ongoing LLM rea-\nsoning process (the history of its thoughts and their states).\n4.1 Prompter\nThe Prompter prepares the prompt to be sent to the LLM.\nThis module is responsible for the specifics of encoding the\ngraph structure within the prompt. The GoT architecture en-\nables the user to implement use-case specific graph encod-\nings by providing full access to the graph structure.\n4.2 Parser\nThe Parser extracts information from LLM\u2019s thoughts. For\neach such thought, the Parser constructs the thought state ,\nwhich contains this extracted information. The thought state\nis then used to update GRS accordingly.\n4.3 Scoring & Validation\nHere, we verify whether a given LLM\u2019s thought satisfies po-\ntential correctness conditions, and then we assign it a score.\nDepending on how the score is derived, the module may\nconsult the LLM.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a581b211-3654-4628-81a1-1ecf1d4827a6": {"__data__": {"id_": "a581b211-3654-4628-81a1-1ecf1d4827a6", "embedding": null, "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db78872b-b53c-4868-a04e-1d03e3198e42", "node_type": "4", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "b0343980c9b13144906459072f9901f5615e2eb3986fa45e772699042ef2dec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f6ff5d4-dab4-44bf-8f45-5a217f8163ef", "node_type": "1", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "54f64124212052b57d24fa878478f22583e32f8e1310780fa657e3cd9b3bc111", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "ab9f16e8391cbed19de27e2cbde19c6b66d188df1dca9f78c6df2894d6269d4b", "class_name": "RelatedNodeInfo"}}, "hash": "d57f23aa30c5accfee0eb2a082b5c7eff9e75257b6101790f6b6e283c75e7f64", "text": "GRS is a dynamic\nstructure that maintains the state of the ongoing LLM rea-\nsoning process (the history of its thoughts and their states).\n4.1 Prompter\nThe Prompter prepares the prompt to be sent to the LLM.\nThis module is responsible for the specifics of encoding the\ngraph structure within the prompt. The GoT architecture en-\nables the user to implement use-case specific graph encod-\nings by providing full access to the graph structure.\n4.2 Parser\nThe Parser extracts information from LLM\u2019s thoughts. For\neach such thought, the Parser constructs the thought state ,\nwhich contains this extracted information. The thought state\nis then used to update GRS accordingly.\n4.3 Scoring & Validation\nHere, we verify whether a given LLM\u2019s thought satisfies po-\ntential correctness conditions, and then we assign it a score.\nDepending on how the score is derived, the module may\nconsult the LLM. Moreover, depending on the use case, the\nscore may also be assigned by a human. Finally, use cases\nsuch as sorting use simple local scoring functions.\n4.4 Controller\nThe Controller implements a specific strategy for select-\ning thoughts from its GRS structure. It also selects what\ntransformations should be applied to which thoughts, and\nthen passes this information to the Prompter. It also decides\nwhether the whole process should be finalized, or whether\nthe next round of interaction with the LLM should be initi-\nated. In our current design, this is dictated by the execution\nplan specified in GoO.\n4.5 GoO & GRS\nThe user constructs a GoO instance, which prescribes the ex-\necution plan of thought operations. GoO is a static structure\nthat is constructed once, before the execution starts. Each\noperation object knows its predecessor operations and suc-\ncessor operations. Then, during the execution, an instance\nof GoO maintains the continually updated information about\nthe LLM reasoning process. This includes which operation\nhas been executed so far, the states of all the generated LLM\nthoughts, their validity and scores, and any other relevant\ninformation.\nThe above elements offer extensible APIs , enabling\nstraightforward implementations of different prompting\nschemes. The APIs are outlines in the green part of Fig-\nure 3, and detailed in the documentation. We also provide\nexamples of prompts used by these operations and a corre-\nsponding GRS in the red part of Figure 3.\n5 Example Use Cases\nWe now describe several use cases of GoT.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e": {"__data__": {"id_": "cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e", "embedding": null, "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03", "node_type": "4", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a30e66d95f9c5aef611e9e9999e56fa6bd324436a56e9f13b9ffaa34a003f4a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a581b211-3654-4628-81a1-1ecf1d4827a6", "node_type": "1", "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d57f23aa30c5accfee0eb2a082b5c7eff9e75257b6101790f6b6e283c75e7f64", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a1a4e13f6f26cc0ce735f6debe281dea8b644e3750d49ba049cab0c6690fc837", "class_name": "RelatedNodeInfo"}}, "hash": "ab9f16e8391cbed19de27e2cbde19c6b66d188df1dca9f78c6df2894d6269d4b", "text": "Goal: Build a prompt\nto be sent to the LLMLegend Architecture overview\nExample prompts and the Graph Reasoning State for the sorting use case (some examples within each prompt are omitted due to space constraints)\nA prompt used byParser\nGoal: Extract\ninformation from\nLLM's thought Goal: Assess the\nquality of the\nLLM's solution\nControllerGoal: Initiate, coordinate, manage,\nand progress the GoT executionExternal entity Prompt Thought\nThought stateScore\nOperation\nThought state + its\nassociated operationsThought state\n+ thought's scoreDependencyModule of the\nGoT system Graph of\nOperations\nGoal: Specify\nLLM thought\ntransformations\nGraph Reasoning State\nGoal: Maintain\nthe ongoing LLM\nreasoning process\nUser\nGoal: Indicate the\ntop-scoring thoughts\nGraph of Operations enables seamless specification of not only\nGoT, but also existing schemes such as CoT, CoT-SC, ToT\nAPI for Prompter (extensible)\n\u27a1 Generate(t,k) //generate a prompt for k new thoughts, using thought t\u27a1 //LLM params: model used, temperature, max tokens, api key, org, ...\n\u27a1 //LLM cost features: prompt token cost, response token cost, ...\n\u27a1 //Instances of Prompter + Parser + Graph of Operations,\n\u27a1 //Any additional input parameters (e.g., numbers to be sorted).\n//Each of the above routines is responsible for parsing an LLM's reply\n//to a corresponding Prompter routine (e.g., ParseScore parses Score).\u27a1 Score(t) //score thought t\n\u27a1 Validate(t) //generate a prompt to validate the correctness of thought t\u27a1 ValidateAndImprove(t) //generate a prompt to enhance thought t,\n\u27a1 Aggregate(t1,...,tk) //generate a prompt to combine thoughts t1, ..., tk API for Controller\nAPI for Parser (extensible)\nParseGenerate, ParseImprove, ParseScore,\nParseAggregate, ParseValidate, ...\u27a1 Generate, Aggregate, Score, ... //see Prompter API\n\u27a1 KeepBest(N) //preserves N best scoring thoughts\n\u27a1 Repeat(k) //Repeat a given operation k times, generating k thoughts.\n    //For example, this enables \"Aggregate\" to generate multiple outcomes\n    //of the combination operation. Each such thought is maintained \n   //within the Graph Reasoning State and scored individually.\nGenerate(t,k=1)+Repeat(k=4)\nAggregate(t1,t2)+Repeat(k=3)+KeepBest(N=1)Available operations when building GoO (extensible)\nSpecifying the Structure of Graph of Operations (GoO)Ranking Scoring &\nvalidationPrompter\nLLM\nHuman\nor LLM\nGray block\nBlue block\nA prompt used by\n<Instruction> Sort the following list of numbers in ascending order.\nOutput only the sorted list of numbers, no additional text. </Instruction>\n<Example>\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, \n2, 0, 9, 3, 3, 9, 2, 1]\nOutput: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, \n6, 6, 7, 7, 8, 8, 9, 9, 9]\n</Example>\nInput: {input}\n<Instruction> Merge the following 2 sorted lists of length {length1} each, \ninto one sorted list of length {length2} using a merge sort style approach.\nOnly output the final merged list without any additional text or thoughts!\n</Instruction>\n<Approach>\nTo merge the two lists in a merge-sort style approach, foloow these steps:\n1. Compare the first element of both lists.\n2. Append the smaller element to the merged list and move to the next \nelement in the list from which the smaller element came.\n3. Repeat steps 1 and 2 until one of the lists is empty.\n4. Append the remaining elements of the non-empty list to the merged list.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b": {"__data__": {"id_": "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b", "embedding": null, "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03", "node_type": "4", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a30e66d95f9c5aef611e9e9999e56fa6bd324436a56e9f13b9ffaa34a003f4a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "ab9f16e8391cbed19de27e2cbde19c6b66d188df1dca9f78c6df2894d6269d4b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3de7b7c3-d159-4d5a-8293-6d094f065c93", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d1e12615ebd00cc051264f07d4b4bbd03f6c38673795c8a0f0b36a3e13fe1fcb", "class_name": "RelatedNodeInfo"}}, "hash": "a1a4e13f6f26cc0ce735f6debe281dea8b644e3750d49ba049cab0c6690fc837", "text": "Only output the final merged list without any additional text or thoughts!\n</Instruction>\n<Approach>\nTo merge the two lists in a merge-sort style approach, foloow these steps:\n1. Compare the first element of both lists.\n2. Append the smaller element to the merged list and move to the next \nelement in the list from which the smaller element came.\n3. Repeat steps 1 and 2 until one of the lists is empty.\n4. Append the remaining elements of the non-empty list to the merged list.\n</Approach>\nMerge the following two lists into one sorted list:\n1: {input1}\n2: {input2}\nMerged list:\nThis prompt is used by an operation Aggregate where the aggregation factor is \nk = 2 (2 input thoughts, t1 and t2, are aggregated). This is repeated by GoT 3 times, \nto maximize quality. Finally, the best result is selected. Note that, in this example, \nthe prompt explicitly requests the merge operation only. All the remaining opera-\ntions are specified in GoO and are handled by the underlying GoT framework.\nThe input\nthought t\nThe input\nthoughts t1, t2\nThis prompt is used by an operation Generate where the\nbranching factor is k=1, which means, only one thought is\ngenerated. However, as we chain it with the operation Repeat\nwith k=4, the underlying GoT framework ensures that Generate\nexecutes 4 times and results in 4 separate thoughts. Note that, from the graph\ntheory perspective, the GRS is identical to that in the operation Generate(t, k=4).\nThe difference between these two is that Generate(t, k=4) gives the user more \ncontrol over how these multiple thoughts are constructed, while Generate(t, \nk=1)+Repeat(k=4) is less flexible but more easy to use. Moreover, with Repeat \none has 4 context-isolated responses from the LLM for identical prompts, \nwhereas without Repeat there is only one context where all 4 thoughts are\ngenerated and must be explicitly handled in a single prompt/session.\nA prompt used by\nGenerate(t,k=4)\n<Instruction> Split the following list of 64 numbers into 4 lists of 16\nnumbers each, the first list should contain the first 16 numbers, the\nsecond list the second 16 numbers, the third list the third 16 numbers\nand the fourth list the fourth 16 numbers. Only output the final 4 lists\nin the following format without any additional text or thoughts!", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3de7b7c3-d159-4d5a-8293-6d094f065c93": {"__data__": {"id_": "3de7b7c3-d159-4d5a-8293-6d094f065c93", "embedding": null, "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03", "node_type": "4", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a30e66d95f9c5aef611e9e9999e56fa6bd324436a56e9f13b9ffaa34a003f4a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a1a4e13f6f26cc0ce735f6debe281dea8b644e3750d49ba049cab0c6690fc837", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10de7e24-d51a-40e5-816b-8216cf308729", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "06071de699089ecd77d8bf505ae43f96caa0e5766ea9f9257a0105fdfdac8855", "class_name": "RelatedNodeInfo"}}, "hash": "d1e12615ebd00cc051264f07d4b4bbd03f6c38673795c8a0f0b36a3e13fe1fcb", "text": "The difference between these two is that Generate(t, k=4) gives the user more \ncontrol over how these multiple thoughts are constructed, while Generate(t, \nk=1)+Repeat(k=4) is less flexible but more easy to use. Moreover, with Repeat \none has 4 context-isolated responses from the LLM for identical prompts, \nwhereas without Repeat there is only one context where all 4 thoughts are\ngenerated and must be explicitly handled in a single prompt/session.\nA prompt used by\nGenerate(t,k=4)\n<Instruction> Split the following list of 64 numbers into 4 lists of 16\nnumbers each, the first list should contain the first 16 numbers, the\nsecond list the second 16 numbers, the third list the third 16 numbers\nand the fourth list the fourth 16 numbers. Only output the final 4 lists\nin the following format without any additional text or thoughts!\n{{\n    \"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\n    \"List 2\": [2, 9, 2, 4, 7, 1, 5, ...],\n    \"List 3\": [6, 9, 8, 1, 9, 2, 4, ...],\n    \"List 4\": [9, 0, 7, 6, 5, 6, 6, ...]\n}} </Instruction>\n<Example>\nInput: [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0, 9, 7, 2, 2, 4, 4, 8, 5, 0, \n8, 7, 3, 3, 8, 7, 0, 9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0, 6, 9, 8, 4, 1, \n2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\nOutput:\n{{\n    \"List 1\": [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0],\n    \"List 2\": [9, 7, 2, 2, 4, 4, 8, 5, 0, 8, 7, 3, 3, 8, 7, 0],\n    \"List 3\": [9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0],\n    \"List 4\": [6, 9, 8, 4, 1, 2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\n}}\n</Example>\nInput: {input}\nThis prompt is used by an operation Generate where\nthe branching factor k = 4. Four new thoughts are\nconstructed based on the LLM reply to this prompt.The input\nthought tImprove(t)+Repeat(k=4)\n<Instruction> The following two lists represent an unsorted list of numbers \nand a sorted variant of that list. The sorted variant is not correct. Fix the \nsorted variant so that it is correct. Make sure that the output list is sorted in\nascending order, has the same number of elements as the input list ({length}),\nand contains the same elements as the input list. </Instruction>\n<Approach>\nTo fix the incorrectly sorted list follow these steps:\n1. For each number from 0 to 9, compare the frequency of that number in the\nincorrectly sorted list to the frequency of that number in the input list.\n2. Iterate through the incorrectly sorted list and add or remove numbers as\nneeded to make the frequency of each number in the incorrectly sorted list\nmatch the frequency of that number in the input list.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10de7e24-d51a-40e5-816b-8216cf308729": {"__data__": {"id_": "10de7e24-d51a-40e5-816b-8216cf308729", "embedding": null, "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03", "node_type": "4", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a30e66d95f9c5aef611e9e9999e56fa6bd324436a56e9f13b9ffaa34a003f4a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3de7b7c3-d159-4d5a-8293-6d094f065c93", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d1e12615ebd00cc051264f07d4b4bbd03f6c38673795c8a0f0b36a3e13fe1fcb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e185aed7-a499-41cf-b47a-78ffc1476c38", "node_type": "1", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "b67c4a2046fd32a2aa52c0bff8fd853ce02f574263c77d7594b5a4d4e9d1c5b3", "class_name": "RelatedNodeInfo"}}, "hash": "06071de699089ecd77d8bf505ae43f96caa0e5766ea9f9257a0105fdfdac8855", "text": "The sorted variant is not correct. Fix the \nsorted variant so that it is correct. Make sure that the output list is sorted in\nascending order, has the same number of elements as the input list ({length}),\nand contains the same elements as the input list. </Instruction>\n<Approach>\nTo fix the incorrectly sorted list follow these steps:\n1. For each number from 0 to 9, compare the frequency of that number in the\nincorrectly sorted list to the frequency of that number in the input list.\n2. Iterate through the incorrectly sorted list and add or remove numbers as\nneeded to make the frequency of each number in the incorrectly sorted list\nmatch the frequency of that number in the input list.\n</Approach>\n<Examples>\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\nIncorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\nReason: The incorrectly sorted list contains four extra 0s, two extra 4s and\nthree extra 9s and is missing two 2s.\nOutput: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9] \n    \nInput: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8,\n3, 9, 5, 6, 1]\nIncorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7,\n7, 7, 8, 8, 9, 9, 9, 9, 9]\nReason: The incorrectly sorted list contains two extra 4s and is missing two\n6s and one 9.\nOutput: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9,\n9, 9, 9, 9, 9]\n</Examples>\nInput: {input}\nIncorrectly Sorted: {incorrectly_sorted}A prompt used by\n...\n...This prompt is used by an operation\nImprove(t), which enhances a given thought t\nusing information provided in another thought.\nDepending on how the Improve + Repeat \noperation is implemented by the user within\nGoT, it can either generate a number of new \nthoughts in GRS (the upper graph on the right), \nsimilar to Generate + Repeat, or may refine \nthe same thought in GRS (the lower graph on \nthe right), chaining k=4 refinement iterations together.\n1 2\n233Initial/system prompt (optional)\nHello. I want to sort the following input sequence of numbers: {input}I\nI\n44\nThe input\nthought t1Figure 3: The system architecture of GoT, and the APIs of respective modules. The user can straightforwardly extend the design\ntowards new prompting schemes, experiment with novel thought transformations, and plug in different LLMs. The blue part of\nthe figure contains the architecture overview, the green part lists the API, and the red part contains example prompts together\nwith a GRS and operations involved.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e185aed7-a499-41cf-b47a-78ffc1476c38": {"__data__": {"id_": "e185aed7-a499-41cf-b47a-78ffc1476c38", "embedding": null, "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e13766eb-e5e8-46ad-acb0-e3c44400bc7d", "node_type": "4", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f8b7ac2e795d87b5b20aa7dec2312e3b3ed25671bf9d021b6529e679aa28c023", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10de7e24-d51a-40e5-816b-8216cf308729", "node_type": "1", "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "06071de699089ecd77d8bf505ae43f96caa0e5766ea9f9257a0105fdfdac8855", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9", "node_type": "1", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f79fa22dc873b4e2109277fee100bbe813f45fe145b83f9cc7371375c7a5f510", "class_name": "RelatedNodeInfo"}}, "hash": "b67c4a2046fd32a2aa52c0bff8fd853ce02f574263c77d7594b5a4d4e9d1c5b3", "text": "5.1 Sorting\nDue to space constraints, we detail one use case (sorting).\nWe focus on its decomposition and Graph of Operations,\nwhich are central for implementing and executing any work-\nload within GoT. We consider sorting numbers 0\u20139 with du-\nplicates. The considered LLMs are unable to sort a sequence\nof such numbers correctly beyond a certain length consis-\ntently because duplicate counts do not match.\nIn GoT, we employ merge-based sorting: First, one de-\ncomposes the input sequence of numbers into subarrays.\nThen, one sorts these subarrays individually, and then re-\nspectively merges them into a final solution. Figure 4 illus-\ntrates this use case together with its graph decomposition.\nHere, an LLM thought is a sequence of sorted numbers.\nTo score an outcome, denote an input sequence with\n[a1, a2, ..., a n]and an output one with [b1, b2, ..., b m]. We\nuse the following score that determines \u201cthe scope\u201d of er-\nrors:\nerror-scope =X+Y\nwhere p\u2208 {1, ..., m},q\u2208 {1, ..., n}, and\nX=m\u22121X\ni=1sgn(max( bi\u2212bi+1,0)),\nY=9X\ni=0| |{bp:bp=i}| \u2212 |{ aq:aq=i}| |\nHere, Xindicates how many consecutive pairs of num-\nbers are incorrectly sorted. If two numbers iandi+ 1\nare incorrectly sorted (i.e., bi> bi+1), then the expression\nwithin the summation returns 1, increasing the error score\nby one. For two numbers correctly sorted, this expression\namounts to 0. Then, Ydetermines how well a given output\nsequence preserves the frequency of output numbers. Specif-\nically, for each considered number x(x\u2208 {0, ...,9}), we\nobtain the difference between the count of input elements\nbeing equal to x, vs. the count of output elements equal\ntox. For an output sequence perfectly preserving the fre-\nquency of x, this would amount to 0. Any single \u201cdevia-\ntion\u201d in this count, increases the \u201cerror scope\u201d by 1). We\nthen sum this over all considered values of x. When plot-\nting this score, to improve the clarity of plots, we addition-\nally apply clipping min( error-scope , n), as some baselines\n(IO, CoT) result in large numbers of outliers with high er-\nror scope. Finally, to use a \u201cpositive score\u201d describing \u201cthe\nscope of correctly sorted\u201d elements, one can use the value\nmax( n\u2212error-scope ,0).\n5.2 Set Operations\nMoreover, we also consider set operations, focusing on set\nintersection. They have numerous applications (particularly\nset intersection) in problems ranging from genome or docu-\nment comparisons to pattern matching [20, 57, 38, 1, 27, 49,\n10, 9]. Set intersection of two sets is implemented similarly\nas the sorting. The second input set is split into subsets and\nthe intersection of those subsets with the first input set is de-\ntermined with the help of the LLM.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9": {"__data__": {"id_": "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9", "embedding": null, "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e13766eb-e5e8-46ad-acb0-e3c44400bc7d", "node_type": "4", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f8b7ac2e795d87b5b20aa7dec2312e3b3ed25671bf9d021b6529e679aa28c023", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e185aed7-a499-41cf-b47a-78ffc1476c38", "node_type": "1", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "b67c4a2046fd32a2aa52c0bff8fd853ce02f574263c77d7594b5a4d4e9d1c5b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "080b7345-b233-4240-ab85-dec8bc6b41cf", "node_type": "1", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "ae1e7e5622ce87868d500e7477ab7268c8ad835208dfd4c2858a3873a2afc16b", "class_name": "RelatedNodeInfo"}}, "hash": "f79fa22dc873b4e2109277fee100bbe813f45fe145b83f9cc7371375c7a5f510", "text": "Finally, to use a \u201cpositive score\u201d describing \u201cthe\nscope of correctly sorted\u201d elements, one can use the value\nmax( n\u2212error-scope ,0).\n5.2 Set Operations\nMoreover, we also consider set operations, focusing on set\nintersection. They have numerous applications (particularly\nset intersection) in problems ranging from genome or docu-\nment comparisons to pattern matching [20, 57, 38, 1, 27, 49,\n10, 9]. Set intersection of two sets is implemented similarly\nas the sorting. The second input set is split into subsets and\nthe intersection of those subsets with the first input set is de-\ntermined with the help of the LLM. Afterwards the resulting\n.....\n.......... .....1 4  ...  4 316 numbers\n8 2  ...  1 316 numbers\n1 1  ...  4 2 1 9  ...  5 416 numbers\n16 numbers\nSort\nPartial solutionGraph of Operations (GoO) for sorting 64 numbers\nPartial solution Partial solution Partial solution\nN = 3Generate(N)\nScoreSort\nGenerate(N)\nSort\nGenerate(N)\n1 2  ...  7 816 numbers\n1 1  ...  5 716 numbers\nPartial solution Partial solution\n1 3  ...  4 816 numbers\nPartial solution\n1 2  ...  7 816 numbers\n1 1  ...  5 716 numbers\nPartial solution Partial solution\n1 3 ... 4 816 numbers\nPartial solution\nScore: 78% Score: 86%\nKeepBest(N)\nKeep the best\nscored thoughtsN = 1\nMerge into a 32\nelement subarray\nAggregate(N)\nN = 10N = 3 N = 3\nAssess how well each sequence is sorted\nHow do we score?64 numbers\n1 4 6 2 4  ...  9 8 7 5 4\nSplitting into four\n16-element chunksGenerate(N) N = 4\nInput\nSort\nGenerate(N)\nN = 3\nScore: 100%\n1 3  ...  4 816 numbers\nPartial solution\nScore: 100%1 3  ...  4 616 numbers\nPartial solution\nScore: 97%..... .....\n.....1 1  ...  8 932 numbers\nPartial solution\nScore: 100%1 3  ...  6 832 numbers\nPartial solution\nScore: 97%\nMerge into a 64\nelement subarray\nAggregate(N)\nN = 2S\nScoreS\nScoreS\nScoreS\nScore\nK\nG\nScoreG\nScoreScore ScoreK K K\nAG\nKA\nAScore\nScore\nK KK KKG\nS\nAKGLegend\nGenerateDetails of the highlighted\npart of GoO are below \nDetails of the highlighted part of GoO from above\nThe first Generate\nsplits the 64-element\ninput array into four\n16-element chunks.\nSorting is implemented within\nthe Generate operation. Here,\nN=3 means that, for each 16\nelement chunk, we generate\nthree different sortings. \nHere, N=1 means that we\nmaintain a single best\nsorting outcome out of\nthe three input ones.\nHere, N=10 means that we try 10 different\naggregations of the two input 16-element subarrays.To obtain the score, for every\nnumber 0 - 9, we get the\ndifference between the input\nand the sorted list, and we sum\nall 10 values. Zero indicates\ncorrectly sorted. To show\n\"the higher the better\", we do\nmax(input_length - score, 0)Note that this is an example graph decomposition. The structure\nof connections between all operations can be arbitrarily modified.\nSort\nKeepBest\nAggregateFigure 4: An example graph decomposition of the sorting\nuse case in GoT. All the used operations (Generate, Aggre-\ngate, Score, KeepBest) are described in Figure 3.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "080b7345-b233-4240-ab85-dec8bc6b41cf": {"__data__": {"id_": "080b7345-b233-4240-ab85-dec8bc6b41cf", "embedding": null, "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0321b819-7f1f-49ea-9981-2a22e01d46cf", "node_type": "4", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "e38948a230d6b345e7da4c067a8fcc420f11c89f81106045cd7e215ba6f3c3d4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9", "node_type": "1", "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f79fa22dc873b4e2109277fee100bbe813f45fe145b83f9cc7371375c7a5f510", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66e11fe4-b35e-48e2-8204-070252f6b48b", "node_type": "1", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "1cf2512379cb3bebb29d1d9391fb83f4fcee61fca89ec6e8632153be6b1ba98c", "class_name": "RelatedNodeInfo"}}, "hash": "ae1e7e5622ce87868d500e7477ab7268c8ad835208dfd4c2858a3873a2afc16b", "text": "intersection sets are aggregated for the final results. For the\nevaluation we use different set sizes of 32, 64 and 128 el-\nements and we vary the number of elements found in both\nsets to be between 25% and 75%.\nOur score indicates the total number of missing or in-\ncorrectly included elements in the final intersection. Specif-\nically, denote two input sets with A= [a1, a2, ..., a n]\nandB= [b1, b2, ..., b n], and the output set with C=\n[c1, c2, ..., c m]. Then,\nerror-scope =X1+X2+Xd\nwhere X1=|C\\(A\u2229B)|are the number of elements in C\nthat are not supposed to be there, X2=|(A\u2229B)\\C|are the\nnumber of elements missing from C, and Xdis the number\nof duplicates in C(because the LLM expresses the set as a\nlist in natural language). Finally, to use a \u201cpositive score\u201d\ndescribing \u201cthe scope of correctly computed\u201d elements, one\ncan use the value max( n\u2212error-scope ,0).\n5.3 Keyword Counting\nKeyword counting finds the frequency of keywords in a\ngiven category (countries in our example implementation)\nwithin the input text. GoT splits the input text into multi-\nple passages, counts the keywords in each passage and ag-\ngregates the sub-results. The number of passages is config-\nurable and can also be left to the LLM, making it possible\nto treat each sentence as a separate passage. Here, to score\na thought, we first \u2013 for each keyword \u2013 derive the absolute\ndifference between the computed count and the correct one.\nWe then sum all these differences to get the final score.\n5.4 Document Merging\nFinally, we also provide document merging. Here, the goal\nis to generate a new Non-Disclosure Agreement (NDA) doc-\nument based on several input ones that partially overlap\nin terms of their contents. The goal is to ensure minimal\namount of duplication, while maximizing information reten-\ntion. Document merging is broadly applicable in, e.g., legal\nprocedures, where multiple sources of information have to\nbe combined into a single document or article. To score a\nsolution, we query the LLM for two values (3 times for each\nvalue, and take the average). The first value corresponds to\nthe solution redundancy (10 indicates no redundancy, 0 im-\nplies at least half the information is redundant), the second\nvalue stands for information retention (10 indicates all infor-\nmation is retained, 0 says that none is retained). We compute\nthe harmonic mean of these values.\n6 The Latency-Volume Tradeoff\nWe now show that GoT improves upon previous prompting\nschemes in terms of the tradeoff between latency (number of\nhops in the graph of thoughts to reach a given final thought)\nandvolume . We define volume \u2013 for a given thought t\u2013 as\nthe number of preceding LLM thoughts that could have im-\npacted t. Formally, the volume of tis the number of thoughts\nfrom which there exists a path to tin the graph of thoughts.\nWe assume that outputting a single thought costs O(1)time\nand fix the total cost to \u0398(n)for each prompting scheme.The structure of the schemes is as follows. CoT-SC con-\nsists of kindependent chains originating from a single start-\ning thought. ToT is a complete k-ary tree. Finally, in GoT, a\ncomplete k-ary tree is joined at its leaves with a \u201cmirrored\u201d\nk-ary tree of the same size but with its edges reversed.\nThe analysis is detailed in Table 2. CoT offers a large vol-\nume of up to N, but at the cost of a high latency of N. CoT-\nSC reduces the latency by a factor of k(which corresponds\nto its branching factor), but it simultaneously decreases the\nvolume by kas well. ToT offers a latency of logkNbut\nalso has low volume. GoT is the only scheme to come with\nboth a low latency of logkNand a high volume N. This\nis enabled by the fact that GoT harnesses aggregations of\nthoughts, making it possible to reach the final thought from\nany other intermediate thought in the graph decomposition.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66e11fe4-b35e-48e2-8204-070252f6b48b": {"__data__": {"id_": "66e11fe4-b35e-48e2-8204-070252f6b48b", "embedding": null, "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0321b819-7f1f-49ea-9981-2a22e01d46cf", "node_type": "4", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "e38948a230d6b345e7da4c067a8fcc420f11c89f81106045cd7e215ba6f3c3d4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "080b7345-b233-4240-ab85-dec8bc6b41cf", "node_type": "1", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "ae1e7e5622ce87868d500e7477ab7268c8ad835208dfd4c2858a3873a2afc16b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "237eb35e-f9dc-4368-9301-e93cfc026298", "node_type": "1", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "196907fc1681fe7c727ad6ed97db8bddc25f07ce2c78770d390bb3a5ed7179b1", "class_name": "RelatedNodeInfo"}}, "hash": "1cf2512379cb3bebb29d1d9391fb83f4fcee61fca89ec6e8632153be6b1ba98c", "text": "ToT is a complete k-ary tree. Finally, in GoT, a\ncomplete k-ary tree is joined at its leaves with a \u201cmirrored\u201d\nk-ary tree of the same size but with its edges reversed.\nThe analysis is detailed in Table 2. CoT offers a large vol-\nume of up to N, but at the cost of a high latency of N. CoT-\nSC reduces the latency by a factor of k(which corresponds\nto its branching factor), but it simultaneously decreases the\nvolume by kas well. ToT offers a latency of logkNbut\nalso has low volume. GoT is the only scheme to come with\nboth a low latency of logkNand a high volume N. This\nis enabled by the fact that GoT harnesses aggregations of\nthoughts, making it possible to reach the final thought from\nany other intermediate thought in the graph decomposition.\nScheme Latency Volume\nChain-of-Thought (CoT) N N\nSelf-Consistency with CoT (CoT-SC) N/k N/k\nTree of Thoughts (ToT) logkN O (logkN)\nGraph of Thoughts (GoT) logkN N\nTable 2: Comparison of prompting schemes, with respect\nto their fundamental tradeoff between latency and volume.\nGoT offers the best tradeoff.\n7 Evaluation\nWe show the advantages of GoT over the state of the art. We\nfocus on comparing GoT to ToT, as it was shown to consis-\ntently outperform other schemes. Still, for a broad compari-\nson, we also experiment with IO, CoT, and CoT-SC. As our\nanalysis results in a large evaluation space, we present rep-\nresentative results and omit data that does not bring relevant\ninsights (e.g., CoT-SC).\n7.1 Evaluation Methodology\nWe use 100 input samples for each task and comparison\nbaseline. We set temperature to be 1.0 and we use 4k con-\ntext unless stated otherwise. For each experiment, we fix the\nnumbers of thoughts in respective schemes to achieve simi-\nlar costs in each experiment.\nParameters We experiment extensively with the branching\nfactor kand the number of levels Lto ensure that we com-\npare GoT to cost-effective and advantageous configurations.\nWe plot two variants of ToT: one with higher kand lower\ndepth (ToT), the other with lower kbut higher L(ToT2).\nWe usually aim to achieve a sweetspot in the tradeoff be-\ntween sparser generation rounds (lower k) vs. more rounds\n(larger L). Usually more responses per round is more expen-\nsive (e.g., 80 vs. 60 total responses for Figure 7 but $6 vs. $3\ncosts). We also try different problem sizes P(e.g., in sorting,\nPstates how many numbers are to be sorted).\nUsed LLMs Due to budget restrictions, we focus on GPT-\n3.5, using GPT-4. We also experimented with Llama-2, but\nit was usually worse than GPT-3.5 and also much slower to\nrun, making it infeasible to obtain enough samples.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "237eb35e-f9dc-4368-9301-e93cfc026298": {"__data__": {"id_": "237eb35e-f9dc-4368-9301-e93cfc026298", "embedding": null, "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3c0b9233-573d-4df6-b237-1c4f8ef62827", "node_type": "4", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a77382de6a74a63714f02c731cfe206d17489720f02fce18b22deb8d34a2fb3d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66e11fe4-b35e-48e2-8204-070252f6b48b", "node_type": "1", "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "1cf2512379cb3bebb29d1d9391fb83f4fcee61fca89ec6e8632153be6b1ba98c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8b74b4c-00ef-4e98-a93f-18efe5b57242", "node_type": "1", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "2c793619bca5493f49de0ec2a7373e0be3c4a772a30fc2bb315150e1416b9383", "class_name": "RelatedNodeInfo"}}, "hash": "196907fc1681fe7c727ad6ed97db8bddc25f07ce2c78770d390bb3a5ed7179b1", "text": "IOCoT ToTToT2 GoT0246810121416#incorrectly sorted elements; the lower the better\n32 elements\n0.00.20.40.60.81.01.21.41.6\nIOCoT ToTToT2 GoT0481216202428323640444852566064\n64 elements\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\n128 elements\n012345678910111213141516\nTotal Cost ($); the lower the betterL=2\nk=20\nL=3\nk=10GoT: Figure 4\nclipped\nL=4\nk=20L=7\nk=10GoT: Figure 4\nclipped\nL=4\nk=20\nL=10\nk=10GoT:\nFigure 4Figure 5: Number of errors and cost in sorting tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see Sections 3.2\nand 6).\n7.2 Analysis of GoT\u2019s Advantages\nThe results of analysis are in Figure 5 (sorting), 6 (set inter-\nsection), 7 (keyword counting), and 8 (document merging);\nsee Section 5 for the description of specific use cases. Over-\nall, GoT improves the quality of outcomes over all the con-\nsidered baselines and it reduces inference costs compared to\nToT.\nGoT vs. ToT GoT improves upon ToT and ToT2 by a\nlarge margin over all the considered problem instances. ToT\nusually comes with somewhat higher quality than ToT2, but\nsimultaneously much higher costs. GoT\u2019s costs are always\nlower than ToT, and comparable (in some cases lower, in\nothers higher) than ToT2. For example, it reduces median er-\nror by \u224862%, thereby achieving a higher quality of sorting,\nforP= 128 in comparison to ToT while ensuring >31%\ncost reductions. These advantages are due to GoT\u2019s ability\nto decompose complex tasks into simpler sub-tasks, solve\nthese sub-tasks independently, and then incrementally merge\nthese outcomes into the final result.\nGoT vs. IO and CoT GoT consistently delivers much\nhigher quality of outcomes than IO/CoT. For example, for\nsorting ( P= 64 ), GoT\u2019s median error is \u224865% and \u224883%\nlower than, respectively, CoT and IO. Yet, the costs of GoT\n\u2013 and ToT \u2013 are much higher than in IO and CoT. This is\nmostly due to our configuration of CoT, where we do not ar-\ntificially inflate the lengths of the chains of reasoning if this\ndoes not improve the outcomes. The higher costs of GoT and\nToT are driven by knew thoughts built for each Generate\noperation; these multiple thoughts are one of the reasons for\nGoT\u2019s superiority in quality.\nIncreasing Complexity of Tackled Problems Most im-\nportantly, the advantages of GoT in the quality increase for\nall the baselines with the growing size of the problem P. For\nexample, in sorting, while for P= 32 GoT only negligibly\nimproves upon ToT2, its median error count becomes lower\nby\u224861% for P= 64 and\u224869% for P= 128 . The quar-\ntiles also become respectively better. The results for other\nschemes also follow the intuition; for example, IO becomesconsistently worse with the increasing P, which is expected\nas a single thought is unlikely to solve a large problem in-\nstance. Overall, this analysis illustrates that GoT is indeed\nwell-suited for elaborate problem cases , as the execution\nschedules usually become more complex with the growing\nproblem sizes.\n7.3 Discussion on Task Decomposition\nWhen splitting a task into subtasks and then solving these\nsubtasks, the size of responses and the input (in tokens) are\nreduced proportionally to the degree of task decomposition.\nHowever, the \u201cstatic\u201d part of the prompt (i.e., few-shot ex-\namples) may become a significant overhead (see GoT4 to\nGoT8 in Figure 7).", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8b74b4c-00ef-4e98-a93f-18efe5b57242": {"__data__": {"id_": "a8b74b4c-00ef-4e98-a93f-18efe5b57242", "embedding": null, "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3c0b9233-573d-4df6-b237-1c4f8ef62827", "node_type": "4", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "a77382de6a74a63714f02c731cfe206d17489720f02fce18b22deb8d34a2fb3d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "237eb35e-f9dc-4368-9301-e93cfc026298", "node_type": "1", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "196907fc1681fe7c727ad6ed97db8bddc25f07ce2c78770d390bb3a5ed7179b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8a80534-d980-4eed-b78b-edf274f61f08", "node_type": "1", "metadata": {"page_label": "9", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "3ef6d30d0fd6c8379ab25ab776aa55d01a126e796458ac29f58085fec0d8c053", "class_name": "RelatedNodeInfo"}}, "hash": "2c793619bca5493f49de0ec2a7373e0be3c4a772a30fc2bb315150e1416b9383", "text": "The quar-\ntiles also become respectively better. The results for other\nschemes also follow the intuition; for example, IO becomesconsistently worse with the increasing P, which is expected\nas a single thought is unlikely to solve a large problem in-\nstance. Overall, this analysis illustrates that GoT is indeed\nwell-suited for elaborate problem cases , as the execution\nschedules usually become more complex with the growing\nproblem sizes.\n7.3 Discussion on Task Decomposition\nWhen splitting a task into subtasks and then solving these\nsubtasks, the size of responses and the input (in tokens) are\nreduced proportionally to the degree of task decomposition.\nHowever, the \u201cstatic\u201d part of the prompt (i.e., few-shot ex-\namples) may become a significant overhead (see GoT4 to\nGoT8 in Figure 7). Here, we observe that these few-shot ex-\namples can usually also be reduced in size (e.g., the passages\nused to demonstrate keyword counting can also be made\nsmaller and still be indicative of the actual input size), thus\nactively working towards decreasing the cost (e.g., see the\ndifference between GoT8 and GoTx in Figure 7).\nThe overall goal when conducting graph decomposition is\nto break down a task to the point, where the LLM can solve\nit correctly for the majority of time using a single prompt\n(or with a few additional improvement steps). This signifi-\ncantly lowers the number of improvement/refinement steps\nneeded during the later stages of the graph exploration. Fur-\nthermore, as indicated by our results, combining or concate-\nnating sub-results is usually an easier task than solving large\ntask instances from scratch. Hence, the LLM is often suc-\ncessful when aggregating the final solution.\n8 Related Work\nWe summarize relations between GoT and related work.\n8.1 Prompting Paradigms & Approaches\nWe detail different prompting paradigms in Section 1 and\nTable 1. There are numerous other work related to prompt-\ning. We now briefly summarize selected most related ones;", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f8a80534-d980-4eed-b78b-edf274f61f08": {"__data__": {"id_": "f8a80534-d980-4eed-b78b-edf274f61f08", "embedding": null, "metadata": {"page_label": "9", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a8cb6ac5-155d-46b8-aeac-6a4db224ec00", "node_type": "4", "metadata": {"page_label": "9", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "c3634df393bbf4ad798a1d56fa9b6590eae14b3d5b3e47b3f4f2ee7696a053ef", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8b74b4c-00ef-4e98-a93f-18efe5b57242", "node_type": "1", "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "2c793619bca5493f49de0ec2a7373e0be3c4a772a30fc2bb315150e1416b9383", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec43fa0e-656a-4cd9-bdc8-05b4b9825692", "node_type": "1", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "177597464e6e697b1e629dfeb055d3969f289dcfe2ad7ebf13a3896317d43e2b", "class_name": "RelatedNodeInfo"}}, "hash": "3ef6d30d0fd6c8379ab25ab776aa55d01a126e796458ac29f58085fec0d8c053", "text": "IOCoT T oTT oT2GoT024681012141618#incorrect elements; the lower the better\n7 6 31 29 4332 elements\n0.00.20.40.60.81.01.21.41.61.8\nIOCoT ToTToT2 GoT048121620242832\n0 0 0 0 464 elements\n0.00.61.21.82.43.03.64.24.8\nIOCoT ToTToT2 GoT0816243240485664728088\n0 0 0 0 0128 elements\n01234567891011\nTotal Cost ($); the lower the betterL=2\nk=20Solved \ncorrectly:\nL=7\nk=10\nL=4\nk=25\nL=9\nk=10L=3\nk=10L=4\nk=20Figure 6: Number of errors and cost in set intersection with ChatGPT-3.5. Landkindicate the structure of ToT (see Sections 3.2\nand 6).\nIO CoT ToT ToT2 GoT4 GoT8 GoTx05101520253035Number of errors; the lower the better\n0 0 1 0 8 7 25\n012345678\nTotal Cost ($); the lower the betterSamples solved\ncorrectly\nSplits the input text into 4 passages, counts\nkeywords in each one, aggregates the sub-\nresults always 2 at a time\nL=4\nk=20\nL=6\nk=10Splits the\ninput into\nsentences\n(each input\nhas 12-19\nsentences)As GoT4, but splits the\ninput text into 8 passages\nFigure 7: Number of errors and cost in keyword counting\nwith ChatGPT-3.5. Landkindicate the structure of ToT (see\nSections 3.2 and 6).\nmore extensive descriptions can be found in dedicated sur-\nveys [68, 40, 69, 34]. Wang et al. proposed Plan-and-\nSolve, an approach to enhance CoT with an explicit plan-\nning stage [65]. Using complexity-based criteria to enhance\nprompting within a CoT was designed by Fu et al. [66, 29].\nThe self-taught reasoner (STaR) [79] generates several chain\nof thoughts, and selects the ones that are valid. Similarly, a\nscheme by Shum et al. [60] generates a pool of CoT candi-\ndates, and selects the best candidate based on whether the\ncandidates match the ground truth and on a policy gradient-\nbased method. Automatic prompt generation overcomes the\nissues of scaling in CoT [58, 42, 41]. Zhou et al. proposes to\nharness selecting the best prompt out of a candidate set [83].\nFinally, in prompt chaining, one cascades different LLMs.\nThis enables prompting different LLMs via different con-\nIO CoT ToT GoT GoT202468Score (out of 10); the higher the better\n03691215\nTotal Cost ($); the lower the betterL=3\nk=10Aggregation of fully\nmerged NDAs\nAggregation\nof partially\nmerged\nNDAsFigure 8: Score and cost in document merging with\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\ntions 3.2 and 6). Number of samples: 50; context size: 16k\ntokens.\ntexts, enabling more powerful reasoning [21, 47, 72, 23, 50,\n71, 72]. GoT is orthogonal to this class of schemes, as it\nfocuses on a single context capabilities.\n8.2 Self-Reflection & Self-Evaluation\nSelf-reflection and self-evaluation were introduced re-\ncently [59, 48, 45, 74]. They are used to enhance differ-\nent tasks, for example for code generation [17] or com-\nputer operation tasks [39]. In GoT, we partially rely on\nself-evaluation when taking decisions on how to expand the\ngraph of thoughts within a prompt.\n8.3 LLMs & Planning\nThere are many works recently on how to plan complex\ntasks with LLMs [36, 80, 77, 75, 67, 37]. GoT could be seen", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec43fa0e-656a-4cd9-bdc8-05b4b9825692": {"__data__": {"id_": "ec43fa0e-656a-4cd9-bdc8-05b4b9825692", "embedding": null, "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07ba6b56-0996-462c-9f05-399dffad92ac", "node_type": "4", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "55bc68ef250e6ec0a2f640fb177d1f83cfd8492b0f152489e4e22f1fd77a81ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8a80534-d980-4eed-b78b-edf274f61f08", "node_type": "1", "metadata": {"page_label": "9", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "3ef6d30d0fd6c8379ab25ab776aa55d01a126e796458ac29f58085fec0d8c053", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4", "node_type": "1", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f229afb4d931bac07bd4907cd9d1f477706b76b01ce1b79090fe058c2c89d27a", "class_name": "RelatedNodeInfo"}}, "hash": "177597464e6e697b1e629dfeb055d3969f289dcfe2ad7ebf13a3896317d43e2b", "text": "as a generic framework that could potentially be used to en-\nhance such schemes, by offering a paradigm for generating\ncomplex graph-based plans.\n8.4 Graphs and Graph Computing\nGraphs have become an immensely popular and important\npart of the general computing landscape [44, 46, 32, 31, 55].\nRecently, there has been a growing interest in domains such\nas graph databases [53, 54, 11, 4, 5, 8], graph pattern match-\ning [25, 18, 61, 10, 2, 1], graph streaming [26, 22, 3],\nand graph machine learning as well as graph neural net-\nworks [33, 73, 82, 81, 16, 33, 12, 6, 30, 56, 7]. The graph\nabstraction has been fruitful for many modern research do-\nmains, such as social sciences (e.g., studying human inter-\nactions), bioinformatics (e.g., analyzing protein structures),\nchemistry (e.g., designing chemical compounds), medicine\n(e.g., drug discovery), cybersecurity (e.g., identifying in-\ntruder machines), healthcare (e.g., exposing groups of peo-\nple who submit fraudulent claims), web graph analysis (e.g.,\nproviding accurate search services), entertainment services\n(e.g., predicting movie popularity), linguistics (e.g., model-\ning relationships between words), transportation (e.g., find-\ning efficient routes), physics (e.g., understanding phase tran-\nsitions and critical phenomena), and many others [44, 20,\n38, 35, 15]. In this work, we harness the graph abstraction\nas a key mechanism that enhances prompting capabilities in\nLLMs.\n9 Conclusion\nPrompt engineering is one of the central new domains of\nthe large language model (LLM) research. It enables using\nLLMs efficiently, without any model updates. However, de-\nsigning effective prompts is a challenging task.\nIn this work, we propose Graph of Thoughts (GoT), a new\nparadigm that enables the LLM to solve different tasks effec-\ntively without any model updates. The key idea is to model\nthe LLM reasoning as an arbitrary graph, where thoughts\nare vertices and dependencies between thoughts are edges.\nThis enables novel transformations of thoughts, such as ag-\ngregation. Human\u2019s task solving is often non-linear, and it\ninvolves combining intermediate solutions into final ones,\nor changing the flow of reasoning upon discovering new in-\nsights. GoT reflects this with its graph structure.\nGoT outperforms other prompting schemes, for example\nensuring 62% increase in the quality of sorting over ToT,\nwhile simultaneously reducing costs by >31%. We also pro-\npose a novel metric for a prompting scheme, the volume of\na thought, to indicate the scope of information that a given\nLLM output could carry with it, where GoT also excels. This\nprovides a step towards more principled prompt engineering.\nThe graph abstraction has been the foundation of several\nsuccessful designs in computing and AI over last decades,\nfor example AlphaFold for protein predictions. Our work\nharnesses it within the realm of prompt engineering.\nAcknowledgements\nWe thank Hussein Harake, Colin McMurtrie, Mark Klein, An-\ngelo Mangili, and the whole CSCS team granting access to theAult and Daint machines, and for their excellent technical sup-\nport. We thank Timo Schneider for help with infrastructure at\nSPCL. This project received funding from the European Re-\nsearch Council (Project PSAP, No. 101002047), and the European\nHigh-Performance Computing Joint Undertaking (JU) under grant\nagreement No. 955513 (MAELSTROM). This project was sup-\nported by the ETH Future Computing Laboratory (EFCL), financed\nby a donation from Huawei Technologies. This project received\nfunding from the European Union\u2019s HE research and innovation\nprogramme under the grant agreement No. 101070141 (Project\nGLACIATION).\nReferences\n[1] M. Besta et al. Graphminesuite: Enabling high-\nperformance and programmable graph mining\nalgorithms with set algebra. arXiv preprint\narXiv:2103.03653 , 2021.\n[2] M. Besta et al. Sisa: Set-centric instruction set ar-\nchitecture for graph mining on processing-in-memory\nsystems. arXiv preprint arXiv:2104.07582 , 2021.\n[3] M. Besta et al.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4": {"__data__": {"id_": "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4", "embedding": null, "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07ba6b56-0996-462c-9f05-399dffad92ac", "node_type": "4", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "55bc68ef250e6ec0a2f640fb177d1f83cfd8492b0f152489e4e22f1fd77a81ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec43fa0e-656a-4cd9-bdc8-05b4b9825692", "node_type": "1", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "177597464e6e697b1e629dfeb055d3969f289dcfe2ad7ebf13a3896317d43e2b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "94b301be-3f3d-49ab-8f0f-784049a06381", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "61bfc89b92a96b1fea8fb6c19ffcdc8906db46e2e56ef0fa66203147b6903c98", "class_name": "RelatedNodeInfo"}}, "hash": "f229afb4d931bac07bd4907cd9d1f477706b76b01ce1b79090fe058c2c89d27a", "text": "955513 (MAELSTROM). This project was sup-\nported by the ETH Future Computing Laboratory (EFCL), financed\nby a donation from Huawei Technologies. This project received\nfunding from the European Union\u2019s HE research and innovation\nprogramme under the grant agreement No. 101070141 (Project\nGLACIATION).\nReferences\n[1] M. Besta et al. Graphminesuite: Enabling high-\nperformance and programmable graph mining\nalgorithms with set algebra. arXiv preprint\narXiv:2103.03653 , 2021.\n[2] M. Besta et al. Sisa: Set-centric instruction set ar-\nchitecture for graph mining on processing-in-memory\nsystems. arXiv preprint arXiv:2104.07582 , 2021.\n[3] M. Besta et al. Practice of streaming processing of\ndynamic graphs: Concepts, models, and systems. IEEE\nTPDS , 2022.\n[4] M. Besta et al. High-performance graph databases that\nare portable, programmable, and scale to hundreds of\nthousands of cores. arXiv preprint arXiv:2305.11162 ,\n2023.\n[5] M. Besta, R. Gerstenberger, N. Blach, M. Fischer, and\nT. Hoefler. Gdi: A graph database interface standard.\nTechnical report, 2023. Available at https://spcl.inf.\nethz.ch/Research/Parallel Programming/GDI/.\n[6] M. Besta, R. Grob, C. Miglioli, N. Bernold, G. Kwas-\nniewski, G. Gjini, R. Kanakagiri, S. Ashkboos, L. Gi-\naninazzi, N. Dryden, et al. Motif prediction with graph\nneural networks. In ACM KDD , 2022.\n[7] M. Besta and T. Hoefler. Parallel and distributed graph\nneural networks: An in-depth concurrency analysis.\narXiv preprint arXiv:2205.09702 , 2022.\n[8] M. Besta, P. Iff, F. Scheidl, K. Osawa, N. Dryden,\nM. Podstawski, T. Chen, and T. Hoefler. Neural graph\ndatabases. In LOG , 2022.\n[9] M. Besta, R. Kanakagiri, H. Mustafa, M. Karasikov,\nG. R \u00a8atsch, T. Hoefler, and E. Solomonik.\nCommunication-efficient jaccard similarity for\nhigh-performance distributed genome comparisons.\narXiv preprint arXiv:1911.04200 , 2019.\n[10] M. Besta, C. Miglioli, P. S. Labini, J. T \u02c7etek, P. Iff,\nR. Kanakagiri, S. Ashkboos, K. Janda, M. Podstawski,\nG. Kwasniewski, et al. Probgraph: High-performance\nand high-accuracy graph mining with probabilistic set\nrepresentations. In ACM/IEEE Supercomputing , 2022.\n[11] M. Besta, E. Peter, R. Gerstenberger, M. Fischer,\nM. Podstawski, C. Barthels, G. Alonso, and T. Hoe-\nfler. Demystifying graph databases: Analysis and tax-\nonomy of data organization, system designs, and graph\nqueries. arXiv preprint arXiv:1910.09017 , 2019.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "94b301be-3f3d-49ab-8f0f-784049a06381": {"__data__": {"id_": "94b301be-3f3d-49ab-8f0f-784049a06381", "embedding": null, "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce", "node_type": "4", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "fdf4d9c1f21d354305bc267456089c937de7830df7c7571f7be60c96d9cfe7da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4", "node_type": "1", "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f229afb4d931bac07bd4907cd9d1f477706b76b01ce1b79090fe058c2c89d27a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3d545973-93b7-48c7-ad3f-8f162e3a2ee4", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "685cbff107bfb4b8785229816da58ed61555835c852607f7127d16cd8c075d28", "class_name": "RelatedNodeInfo"}}, "hash": "61bfc89b92a96b1fea8fb6c19ffcdc8906db46e2e56ef0fa66203147b6903c98", "text": "[12] M. M. Bronstein, J. Bruna, Y . LeCun, A. Szlam, and\nP. Vandergheynst. Geometric deep learning: going be-\nyond euclidean data. IEEE Signal Processing Maga-\nzine, 34(4):18\u201342, 2017.\n[13] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Ka-\nplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sas-\ntry, A. Askell, et al. Language models are few-shot\nlearners. Advances in neural information processing\nsystems , 33:1877\u20131901, 2020.\n[14] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke,\nE. Horvitz, E. Kamar, P. Lee, Y . T. Lee, Y . Li,\nS. Lundberg, et al. Sparks of artificial general intelli-\ngence: Early experiments with GPT-4. arXiv preprint\narXiv:2303.12712 , 2023.\n[15] D. Chakrabarti and C. Faloutsos. Graph mining: Laws,\ngenerators, and algorithms. ACM computing surveys\n(CSUR) , 38(1):2, 2006.\n[16] I. Chami, S. Abu-El-Haija, B. Perozzi, C. R \u00b4e,\nand K. Murphy. Machine learning on graphs: A\nmodel and comprehensive taxonomy. arXiv preprint\narXiv:2005.03675 , 2020.\n[17] X. Chen, M. Lin, N. Sch \u00a8arli, and D. Zhou. Teaching\nlarge language models to self-debug. arXiv preprint\narXiv:2304.05128 , 2023.\n[18] J. Cheng, J. X. Yu, B. Ding, S. Y . Philip, and H. Wang.\nFast graph pattern matching. In 2008 IEEE 24th Inter-\nnational Conference on Data Engineering , pages 913\u2013\n922. IEEE, 2008.\n[19] A. Chowdhery, S. Narang, J. Devlin, M. Bosma,\nG. Mishra, A. Roberts, P. Barham, H. W. Chung,\nC. Sutton, S. Gehrmann, et al. Palm: Scaling lan-\nguage modeling with pathways. arXiv preprint\narXiv:2204.02311 , 2022.\n[20] D. J. Cook and L. B. Holder. Mining graph data . John\nWiley & Sons, 2006.\n[21] A. Creswell, M. Shanahan, and I. Higgins. Selection-\ninference: Exploiting large language models for\ninterpretable logical reasoning. arXiv preprint\narXiv:2205.09712 , 2022.\n[22] L. Dhulipala et al. Low-latency graph stream-\ning using compressed purely-functional trees.\narXiv:1904.08380 , 2019.\n[23] D. Dohan, W. Xu, A. Lewkowycz, J. Austin, D. Bieber,\nR. G. Lopes, Y . Wu, H. Michalewski, R. A. Saurous,\nJ. Sohl-Dickstein, et al. Language model cascades.\narXiv preprint arXiv:2207.10342 , 2022.\n[24] I. Drori, S. Zhang, R. Shuttleworth, L. Tang, A. Lu,\nE. Ke, K. Liu, L. Chen, S. Tran, N. Cheng, et al. A\nneural network solves, explains, and generates univer-\nsity math problems by program synthesis and few-shot\nlearning at human level. Proceedings of the National\nAcademy of Sciences , 119(32):e2123433119, 2022.\n[25] W. Fan, J. Li, S. Ma, N. Tang, Y . Wu, and Y . Wu.\nGraph pattern matching: from intractable to polyno-\nmial time.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3d545973-93b7-48c7-ad3f-8f162e3a2ee4": {"__data__": {"id_": "3d545973-93b7-48c7-ad3f-8f162e3a2ee4", "embedding": null, "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce", "node_type": "4", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "fdf4d9c1f21d354305bc267456089c937de7830df7c7571f7be60c96d9cfe7da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "94b301be-3f3d-49ab-8f0f-784049a06381", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "61bfc89b92a96b1fea8fb6c19ffcdc8906db46e2e56ef0fa66203147b6903c98", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad454172-605f-4f9b-8773-ea3312e6f21d", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "88c572b4fb2e55f2b153dab8df7b60d3bdd64279dd0a37f573d5b17d4dd6d81f", "class_name": "RelatedNodeInfo"}}, "hash": "685cbff107bfb4b8785229816da58ed61555835c852607f7127d16cd8c075d28", "text": "Language model cascades.\narXiv preprint arXiv:2207.10342 , 2022.\n[24] I. Drori, S. Zhang, R. Shuttleworth, L. Tang, A. Lu,\nE. Ke, K. Liu, L. Chen, S. Tran, N. Cheng, et al. A\nneural network solves, explains, and generates univer-\nsity math problems by program synthesis and few-shot\nlearning at human level. Proceedings of the National\nAcademy of Sciences , 119(32):e2123433119, 2022.\n[25] W. Fan, J. Li, S. Ma, N. Tang, Y . Wu, and Y . Wu.\nGraph pattern matching: from intractable to polyno-\nmial time. Proceedings of the VLDB Endowment , 3(1-\n2):264\u2013275, 2010.[26] G. Feng et al. Distinger: A distributed graph data struc-\nture for massive dynamic graph processing. In IEEE\nBig Data , pages 1814\u20131822, 2015.\n[27] A. Friggeri, G. Chelius, and E. Fleury. Triangles to\ncapture social cohesion. In 2011 IEEE Third Interna-\ntional Conference on Privacy, Security, Risk and Trust\nand 2011 IEEE Third International Conference on So-\ncial Computing , pages 258\u2013265. IEEE, 2011.\n[28] K. Friston. Hierarchical models in the brain. PLoS\ncomputational biology , 4(11):e1000211, 2008.\n[29] Y . Fu, H. Peng, A. Sabharwal, P. Clark, and T. Khot.\nComplexity-based prompting for multi-step reasoning.\narXiv preprint arXiv:2210.00720 , 2022.\n[30] L. Gianinazzi, M. Fries, N. Dryden, T. Ben-Nun, and\nT. Hoefler. Learning combinatorial node labeling algo-\nrithms. arXiv preprint arXiv:2106.03594 , 2021.\n[31] D. Gregor and A. Lumsdaine. Lifting sequential graph\nalgorithms for distributed-memory parallel computa-\ntion. ACM SIGPLAN Notices , 40(10):423\u2013437, 2005.\n[32] D. Gregor and A. Lumsdaine. The parallel bgl:\nA generic library for distributed graph computations.\nPOOSC , 2005.\n[33] W. L. Hamilton et al. Representation learning on\ngraphs: Methods and applications. arXiv preprint\narXiv:1709.05584 , 2017.\n[34] M. Hartmann and D. Sonntag. A survey on improving\nnlp models with human explanations. arXiv preprint\narXiv:2204.08892 , 2022.\n[35] T. Horv \u00b4ath, T. G \u00a8artner, and S. Wrobel. Cyclic pattern\nkernels for predictive graph mining. In KDD , pages\n158\u2013167. ACM, 2004.\n[36] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Lan-\nguage models as zero-shot planners: Extracting action-\nable knowledge for embodied agents. In International\nConference on Machine Learning , pages 9118\u20139147.\nPMLR, 2022.\n[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Flo-\nrence, A. Zeng, J. Tompson, I. Mordatch, Y . Cheb-\notar, et al. Inner monologue: Embodied reason-\ning through planning with language models. arXiv\npreprint arXiv:2207.05608 , 2022.\n[38] C. Jiang, F. Coenen, and M. Zito. A survey of fre-\nquent subgraph mining algorithms. The Knowledge\nEngineering Review , 28(1):75\u2013105, 2013.\n[39] G. Kim, P. Baldi, and S. McAleer. Language\nmodels can solve computer tasks. arXiv preprint\narXiv:2303.17491 , 2023.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad454172-605f-4f9b-8773-ea3312e6f21d": {"__data__": {"id_": "ad454172-605f-4f9b-8773-ea3312e6f21d", "embedding": null, "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce", "node_type": "4", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "fdf4d9c1f21d354305bc267456089c937de7830df7c7571f7be60c96d9cfe7da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3d545973-93b7-48c7-ad3f-8f162e3a2ee4", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "685cbff107bfb4b8785229816da58ed61555835c852607f7127d16cd8c075d28", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0302f01-098c-4050-9b93-531867499d52", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "21c79047c1b6ce9f21ad273a4ed813cb7ec0fb239d3927b14ac670305793f71b", "class_name": "RelatedNodeInfo"}}, "hash": "88c572b4fb2e55f2b153dab8df7b60d3bdd64279dd0a37f573d5b17d4dd6d81f", "text": "[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Flo-\nrence, A. Zeng, J. Tompson, I. Mordatch, Y . Cheb-\notar, et al. Inner monologue: Embodied reason-\ning through planning with language models. arXiv\npreprint arXiv:2207.05608 , 2022.\n[38] C. Jiang, F. Coenen, and M. Zito. A survey of fre-\nquent subgraph mining algorithms. The Knowledge\nEngineering Review , 28(1):75\u2013105, 2013.\n[39] G. Kim, P. Baldi, and S. McAleer. Language\nmodels can solve computer tasks. arXiv preprint\narXiv:2303.17491 , 2023.\n[40] P. Lertvittayakumjorn and F. Toni. Explanation-based\nhuman debugging of nlp models: A survey. Transac-\ntions of the Association for Computational Linguistics ,\n9:1508\u20131528, 2021.\n[41] B. Lester, R. Al-Rfou, and N. Constant. The power\nof scale for parameter-efficient prompt tuning. arXiv\npreprint arXiv:2104.08691 , 2021.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c0302f01-098c-4050-9b93-531867499d52": {"__data__": {"id_": "c0302f01-098c-4050-9b93-531867499d52", "embedding": null, "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28", "node_type": "4", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "84b574a2dfc95f9db014eeace2366e2a56a3b51fc9e92438725c2f70d78560d8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad454172-605f-4f9b-8773-ea3312e6f21d", "node_type": "1", "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "88c572b4fb2e55f2b153dab8df7b60d3bdd64279dd0a37f573d5b17d4dd6d81f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "24bbbdf107c788e381abec2ff6518f2fbcd7cfd05a7f28b6419cbe2f273a9529", "class_name": "RelatedNodeInfo"}}, "hash": "21c79047c1b6ce9f21ad273a4ed813cb7ec0fb239d3927b14ac670305793f71b", "text": "[42] X. L. Li and P. Liang. Prefix-tuning: Optimizing\ncontinuous prompts for generation. arXiv preprint\narXiv:2101.00190 , 2021.\n[43] J. Long. Large language model guided tree-of-thought.\narXiv preprint arXiv:2305.08291 , 2023.\n[44] A. Lumsdaine, D. Gregor, B. Hendrickson, and\nJ. Berry. Challenges in parallel graph processing. Par-\nallel Processing Letters , 17(01):5\u201320, 2007.\n[45] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao,\nS. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye,\nY . Yang, et al. Self-refine: Iterative refinement with\nself-feedback. arXiv preprint arXiv:2303.17651 , 2023.\n[46] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert,\nI. Horn, N. Leiser, and G. Czajkowski. Pregel: a system\nfor large-scale graph processing. In ACM SIGMOD ,\npages 135\u2013146. ACM, 2010.\n[47] M. Nye, A. J. Andreassen, G. Gur-Ari,\nH. Michalewski, J. Austin, D. Bieber, D. Dohan,\nA. Lewkowycz, M. Bosma, D. Luan, et al. Show your\nwork: Scratchpads for intermediate computation with\nlanguage models. arXiv preprint arXiv:2112.00114 ,\n2021.\n[48] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges,\nA. Bosselut, R. West, and B. Faltings. Refiner: Reason-\ning feedback on intermediate representations. arXiv\npreprint arXiv:2304.01904 , 2023.\n[49] A. Prat-P \u00b4erez, D. Dominguez-Sal, J. M. Brunat, and J.-\nL. Larriba-Pey. Shaping communities out of triangles.\nInProceedings of the 21st ACM international con-\nference on Information and knowledge management ,\npages 1677\u20131681, 2012.\n[50] S. Qiao, Y . Ou, N. Zhang, X. Chen, Y . Yao, S. Deng,\nC. Tan, F. Huang, and H. Chen. Reasoning with lan-\nguage model prompting: A survey. arXiv preprint\narXiv:2212.09597 , 2022.\n[51] A. Radford, K. Narasimhan, T. Salimans, and\nI. Sutskever. Improving language understanding by\ngenerative pre-training, 2018.\n[52] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei,\nI. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog , 1(8):9, 2019.\n[53] I. Robinson, J. Webber, and E. Eifrem. Graph\ndatabases . \u201d O\u2019Reilly Media, Inc.\u201d, 2013.\n[54] I. Robinson, J. Webber, and E. Eifrem. Graph\ndatabases: new opportunities for connected data . \u201d\nO\u2019Reilly Media, Inc.\u201d, 2015.\n[55] S. Sakr et al. The future is big graphs! a commu-\nnity view on graph processing systems. arXiv preprint\narXiv:2012.06171 , 2020.\n[56] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner,\nand G. Monfardini. The graph neural network model.\nIEEE transactions on neural networks , 20(1):61\u201380,\n2008.\n[57] S. E. Schaeffer. Graph clustering. Computer science\nreview , 1(1):27\u201364, 2007.[58] T. Shin, Y .", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d": {"__data__": {"id_": "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d", "embedding": null, "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28", "node_type": "4", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "84b574a2dfc95f9db014eeace2366e2a56a3b51fc9e92438725c2f70d78560d8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0302f01-098c-4050-9b93-531867499d52", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "21c79047c1b6ce9f21ad273a4ed813cb7ec0fb239d3927b14ac670305793f71b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07067ef5-479b-47ab-9f5a-a5180b1c5be8", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "2cc6d6411b1785751f318abc9f88a11f37feaa19b4337c7426d687c0944523c2", "class_name": "RelatedNodeInfo"}}, "hash": "24bbbdf107c788e381abec2ff6518f2fbcd7cfd05a7f28b6419cbe2f273a9529", "text": "Graph\ndatabases: new opportunities for connected data . \u201d\nO\u2019Reilly Media, Inc.\u201d, 2015.\n[55] S. Sakr et al. The future is big graphs! a commu-\nnity view on graph processing systems. arXiv preprint\narXiv:2012.06171 , 2020.\n[56] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner,\nand G. Monfardini. The graph neural network model.\nIEEE transactions on neural networks , 20(1):61\u201380,\n2008.\n[57] S. E. Schaeffer. Graph clustering. Computer science\nreview , 1(1):27\u201364, 2007.[58] T. Shin, Y . Razeghi, R. L. Logan IV , E. Wallace, and\nS. Singh. Autoprompt: Eliciting knowledge from lan-\nguage models with automatically generated prompts.\narXiv preprint arXiv:2010.15980 , 2020.\n[59] N. Shinn, B. Labash, and A. Gopinath. Reflexion:\nan autonomous agent with dynamic memory and self-\nreflection. arXiv preprint arXiv:2303.11366 , 2023.\n[60] K. Shum, S. Diao, and T. Zhang. Automatic prompt\naugmentation and selection with chain-of-thought\nfrom labeled data. arXiv preprint arXiv:2302.12822 ,\n2023.\n[61] C. H. Teixeira, A. J. Fonseca, M. Serafini, G. Siganos,\nM. J. Zaki, and A. Aboulnaga. Arabesque: a sys-\ntem for distributed graph mining. In Proceedings of\nthe 25th Symposium on Operating Systems Principles ,\npages 425\u2013440. ACM, 2015.\n[62] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A.\nLachaux, T. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro,\nF. Azhar, et al. Llama: Open and efficient foundation\nlanguage models. arXiv preprint arXiv:2302.13971 ,\n2023.\n[63] H. Touvron, L. Martin, K. Stone, P. Albert, A. Alma-\nhairi, Y . Babaei, N. Bashlykov, S. Batra, P. Bhargava,\nS. Bhosale, et al. Llama 2: Open foundation and fine-\ntuned chat models. arXiv preprint arXiv:2307.09288 ,\n2023.\n[64] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin.\nAttention is all you need. In NeurIPS , 2017.\n[65] L. Wang, W. Xu, Y . Lan, Z. Hu, Y . Lan, R. K.-W.\nLee, and E.-P. Lim. Plan-and-solve prompting: Im-\nproving zero-shot chain-of-thought reasoning by large\nlanguage models. arXiv preprint arXiv:2305.04091 ,\n2023.\n[66] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi,\nand D. Zhou. Self-consistency improves chain of\nthought reasoning in language models. arXiv preprint\narXiv:2203.11171 , 2022.\n[67] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. De-\nscribe, explain, plan and select: Interactive planning\nwith large language models enables open-world multi-\ntask agents. arXiv preprint arXiv:2302.01560 , 2023.\n[68] Z. Wang, G. Zhang, K. Yang, N. Shi, W. Zhou, S. Hao,\nG. Xiong, Y . Li, M. Y . Sim, X. Chen, et al. In-\nteractive natural language processing.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07067ef5-479b-47ab-9f5a-a5180b1c5be8": {"__data__": {"id_": "07067ef5-479b-47ab-9f5a-a5180b1c5be8", "embedding": null, "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28", "node_type": "4", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "84b574a2dfc95f9db014eeace2366e2a56a3b51fc9e92438725c2f70d78560d8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "24bbbdf107c788e381abec2ff6518f2fbcd7cfd05a7f28b6419cbe2f273a9529", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee3939d8-f788-4f1e-a812-0e74452b5c8a", "node_type": "1", "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f69c812b94c7bf559c928717e69ed40304c6c9e1fc25b2bf895d22cb848ae30e", "class_name": "RelatedNodeInfo"}}, "hash": "2cc6d6411b1785751f318abc9f88a11f37feaa19b4337c7426d687c0944523c2", "text": "[66] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi,\nand D. Zhou. Self-consistency improves chain of\nthought reasoning in language models. arXiv preprint\narXiv:2203.11171 , 2022.\n[67] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. De-\nscribe, explain, plan and select: Interactive planning\nwith large language models enables open-world multi-\ntask agents. arXiv preprint arXiv:2302.01560 , 2023.\n[68] Z. Wang, G. Zhang, K. Yang, N. Shi, W. Zhou, S. Hao,\nG. Xiong, Y . Li, M. Y . Sim, X. Chen, et al. In-\nteractive natural language processing. arXiv preprint\narXiv:2305.13246 , 2023.\n[69] Z. J. Wang, D. Choi, S. Xu, and D. Yang. Putting hu-\nmans in the natural language processing loop: A sur-\nvey. arXiv preprint arXiv:2103.04044 , 2021.\n[70] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi,\nQ. Le, and D. Zhou. Chain of thought prompting elic-\nits reasoning in large language models. arXiv preprint\narXiv:2201.11903 , 2022.\n[71] T. Wu, E. Jiang, A. Donsbach, J. Gray, A. Molina,\nM. Terry, and C. J. Cai. Promptchainer: Chaining large\nlanguage model prompts through visual programming.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee3939d8-f788-4f1e-a812-0e74452b5c8a": {"__data__": {"id_": "ee3939d8-f788-4f1e-a812-0e74452b5c8a", "embedding": null, "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "41509996-f13e-436a-aaaa-166140364176", "node_type": "4", "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d83ba17130c816b5b6fd9777dfbba639b53eb9d4f4db7e90e483ca83048ad8d5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07067ef5-479b-47ab-9f5a-a5180b1c5be8", "node_type": "1", "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "2cc6d6411b1785751f318abc9f88a11f37feaa19b4337c7426d687c0944523c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "201ed5e8-19c9-4b48-835d-21828270b811", "node_type": "1", "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "357a6eae27302ab78ad767836884a8ea6507a3960c11bbff765e411bc00d85c8", "class_name": "RelatedNodeInfo"}}, "hash": "f69c812b94c7bf559c928717e69ed40304c6c9e1fc25b2bf895d22cb848ae30e", "text": "InCHI Conference on Human Factors in Computing\nSystems Extended Abstracts , pages 1\u201310, 2022.\n[72] T. Wu, M. Terry, and C. J. Cai. AI chains: Transpar-\nent and controllable human-AI interaction by chaining\nlarge language model prompts. In Proceedings of the\n2022 CHI Conference on Human Factors in Comput-\ning Systems , pages 1\u201322, 2022.\n[73] Z. Wu et al. A comprehensive survey on graph neural\nnetworks. IEEE Transactions on Neural Networks and\nLearning Systems , 2020.\n[74] Y . Xie, K. Kawaguchi, Y . Zhao, X. Zhao, M.-Y . Kan,\nJ. He, and Q. Xie. Decomposition enhances reason-\ning via self-evaluation guided decoding. arXiv preprint\narXiv:2305.00633 , 2023.\n[75] S. Yang, O. Nachum, Y . Du, J. Wei, P. Abbeel, and\nD. Schuurmans. Foundation models for decision mak-\ning: Problems, methods, and opportunities. arXiv\npreprint arXiv:2303.04129 , 2023.\n[76] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths,\nY . Cao, and K. Narasimhan. Tree of thoughts: Deliber-\nate problem solving with large language models. arXiv\npreprint arXiv:2305.10601 , 2023.\n[77] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran,\nK. Narasimhan, and Y . Cao. React: Synergizing rea-\nsoning and acting in language models. arXiv preprint\narXiv:2210.03629 , 2022.\n[78] Y . Yao, Z. Li, and H. Zhao. Beyond chain-of-thought,\neffective graph-of-thought reasoning in large language\nmodels. arXiv preprint arXiv:2305.16582 , 2023.\n[79] E. Zelikman, Y . Wu, J. Mu, and N. Goodman. Star:\nBootstrapping reasoning with reasoning. Advances\nin Neural Information Processing Systems , 35:15476\u2013\n15488, 2022.\n[80] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum,\nand C. Gan. Planning with large language models\nfor code generation. arXiv preprint arXiv:2303.05510 ,\n2023.\n[81] Z. Zhang, P. Cui, and W. Zhu. Deep learning on graphs:\nA survey. IEEE Transactions on Knowledge and Data\nEngineering , 2020.\n[82] J. Zhou et al. Graph neural networks: A review of\nmethods and applications. AI Open , 1:57\u201381, 2020.\n[83] Y . Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis,\nH. Chan, and J. Ba. Large language models\nare human-level prompt engineers. arXiv preprint\narXiv:2211.01910 , 2022.A Positive Score Evaluation\nThe following figures plot the same data as Figures 5 and 6\nrespectively, however use the \u201dpositive score\u201d described in\nSections 5.1 and 5.2.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "201ed5e8-19c9-4b48-835d-21828270b811": {"__data__": {"id_": "201ed5e8-19c9-4b48-835d-21828270b811", "embedding": null, "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "41509996-f13e-436a-aaaa-166140364176", "node_type": "4", "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "d83ba17130c816b5b6fd9777dfbba639b53eb9d4f4db7e90e483ca83048ad8d5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee3939d8-f788-4f1e-a812-0e74452b5c8a", "node_type": "1", "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}, "hash": "f69c812b94c7bf559c928717e69ed40304c6c9e1fc25b2bf895d22cb848ae30e", "class_name": "RelatedNodeInfo"}}, "hash": "357a6eae27302ab78ad767836884a8ea6507a3960c11bbff765e411bc00d85c8", "text": "[81] Z. Zhang, P. Cui, and W. Zhu. Deep learning on graphs:\nA survey. IEEE Transactions on Knowledge and Data\nEngineering , 2020.\n[82] J. Zhou et al. Graph neural networks: A review of\nmethods and applications. AI Open , 1:57\u201381, 2020.\n[83] Y . Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis,\nH. Chan, and J. Ba. Large language models\nare human-level prompt engineers. arXiv preprint\narXiv:2211.01910 , 2022.A Positive Score Evaluation\nThe following figures plot the same data as Figures 5 and 6\nrespectively, however use the \u201dpositive score\u201d described in\nSections 5.1 and 5.2.\nIOCoT ToTToT2 GoT0481216202428323640444852566064\n64 elements\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\n128 elements\n012345678910111213141516\nTotal Cost ($); the lower the better\nIOCoT ToTToT2 GoT161820222426283032#correct elements; the higher the better\n32 elements\n0.00.20.40.60.81.01.21.41.6L=2\nk=20\nL=3\nk=10GoT: Figure 4 GoT: Figure 4 GoT: Figure 4\nL=4\nk=20L=7\nk=10L=4\nk=20\nL=10\nk=10\nFigure 9: Accuracy and cost in sorting tasks with ChatGPT-\n3.5.Landkindicate the structure of ToT (see Sections 3.2\nand 6).\nIOCoT ToTToT2 GoT8101214161820222426283032#correct elements; the higher the better\n7 6 31 29 4332 elements\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\nIOCoT ToTToT2 GoT16202428323640444852566064\n0 0 0 0 464 elements\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\n0 0 0 0 0128 elements\n0.00.51.01.52.02.53.03.54.04.55.05.56.06.57.07.58.0\nTotal Cost ($); the lower the betterL=2\nk=20\nL=3\nk=10Samples\nsolved\ncorrectly:\nL=4\nk=20L=7\nk=10L=4\nk=25L=9\nk=10\nFigure 10: Accuracy and cost in set intersection with\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\ntions 3.2 and 6).", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"9ca2a1d0-3497-481b-bce2-e039f68cffd2": {"node_ids": ["6485898a-5c5f-4be4-b369-3d6d7cf0c8a0", "869df95b-1f65-4331-a246-91ca55433845"], "metadata": {"page_label": "1", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "ef5bc24e-11ab-42d6-b1c5-4db1ff1239cc": {"node_ids": ["564b697d-6daf-42ed-863b-b70d68409e88", "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514"], "metadata": {"page_label": "2", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "79786b26-060e-4428-85c2-d57843c47428": {"node_ids": ["0148c831-ddb5-41c4-b1b9-5a29081f6a88", "eb975f7b-b67e-4b6f-bdcb-cf417891ac90"], "metadata": {"page_label": "3", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "db78872b-b53c-4868-a04e-1d03e3198e42": {"node_ids": ["4f6ff5d4-dab4-44bf-8f45-5a217f8163ef", "a581b211-3654-4628-81a1-1ecf1d4827a6"], "metadata": {"page_label": "4", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03": {"node_ids": ["cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e", "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b", "3de7b7c3-d159-4d5a-8293-6d094f065c93", "10de7e24-d51a-40e5-816b-8216cf308729"], "metadata": {"page_label": "5", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "e13766eb-e5e8-46ad-acb0-e3c44400bc7d": {"node_ids": ["e185aed7-a499-41cf-b47a-78ffc1476c38", "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9"], "metadata": {"page_label": "6", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "0321b819-7f1f-49ea-9981-2a22e01d46cf": {"node_ids": ["080b7345-b233-4240-ab85-dec8bc6b41cf", "66e11fe4-b35e-48e2-8204-070252f6b48b"], "metadata": {"page_label": "7", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "3c0b9233-573d-4df6-b237-1c4f8ef62827": {"node_ids": ["237eb35e-f9dc-4368-9301-e93cfc026298", "a8b74b4c-00ef-4e98-a93f-18efe5b57242"], "metadata": {"page_label": "8", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "a8cb6ac5-155d-46b8-aeac-6a4db224ec00": {"node_ids": ["f8a80534-d980-4eed-b78b-edf274f61f08"], "metadata": {"page_label": "9", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "07ba6b56-0996-462c-9f05-399dffad92ac": {"node_ids": ["ec43fa0e-656a-4cd9-bdc8-05b4b9825692", "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4"], "metadata": {"page_label": "10", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "66c5e0d0-348a-40e6-867e-d1746d9673ce": {"node_ids": ["94b301be-3f3d-49ab-8f0f-784049a06381", "3d545973-93b7-48c7-ad3f-8f162e3a2ee4", "ad454172-605f-4f9b-8773-ea3312e6f21d"], "metadata": {"page_label": "11", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "ddd18cc5-dfdc-414a-92d7-6511e3cfee28": {"node_ids": ["c0302f01-098c-4050-9b93-531867499d52", "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d", "07067ef5-479b-47ab-9f5a-a5180b1c5be8"], "metadata": {"page_label": "12", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}, "41509996-f13e-436a-aaaa-166140364176": {"node_ids": ["ee3939d8-f788-4f1e-a812-0e74452b5c8a", "201ed5e8-19c9-4b48-835d-21828270b811"], "metadata": {"page_label": "13", "file_name": "graph_of_thoughts.pdf", "file_path": "src_docs/current_subset/graph_of_thoughts.pdf", "file_type": "application/pdf", "file_size": 2838941, "creation_date": "2023-11-25", "last_modified_date": "2023-11-25", "last_accessed_date": "2023-11-25"}}}, "docstore/metadata": {"6485898a-5c5f-4be4-b369-3d6d7cf0c8a0": {"doc_hash": "47c8394548352ef46e14ae0026c5591a46028b486caa7a844463eab07490d474", "ref_doc_id": "9ca2a1d0-3497-481b-bce2-e039f68cffd2"}, "869df95b-1f65-4331-a246-91ca55433845": {"doc_hash": "9ebccb17124cb43a671808672bca1d209e208d3cfc35aaa269725adf940a213e", "ref_doc_id": "9ca2a1d0-3497-481b-bce2-e039f68cffd2"}, "564b697d-6daf-42ed-863b-b70d68409e88": {"doc_hash": "1a9839901b431bb42d48d8158ffc3dc01e6c115b3350edab5166b6ba10b196cd", "ref_doc_id": "ef5bc24e-11ab-42d6-b1c5-4db1ff1239cc"}, "1c9c6c7e-f63b-4e2d-b0b8-79ea99307514": {"doc_hash": "3a1000dda82df60ab1f5d58e1ffb30d9b639763048f318ac72a217581a0a169a", "ref_doc_id": "ef5bc24e-11ab-42d6-b1c5-4db1ff1239cc"}, "0148c831-ddb5-41c4-b1b9-5a29081f6a88": {"doc_hash": "7d454f0ae7250b156221c382d2863a4651211579410b4630b6bb762183e49be1", "ref_doc_id": "79786b26-060e-4428-85c2-d57843c47428"}, "eb975f7b-b67e-4b6f-bdcb-cf417891ac90": {"doc_hash": "17f03eecf8c35c928d8bb12f9f22c162f36d339a589ea60ed25aae61c0b3ea5d", "ref_doc_id": "79786b26-060e-4428-85c2-d57843c47428"}, "4f6ff5d4-dab4-44bf-8f45-5a217f8163ef": {"doc_hash": "54f64124212052b57d24fa878478f22583e32f8e1310780fa657e3cd9b3bc111", "ref_doc_id": "db78872b-b53c-4868-a04e-1d03e3198e42"}, "a581b211-3654-4628-81a1-1ecf1d4827a6": {"doc_hash": "d57f23aa30c5accfee0eb2a082b5c7eff9e75257b6101790f6b6e283c75e7f64", "ref_doc_id": "db78872b-b53c-4868-a04e-1d03e3198e42"}, "cd4dba50-a3d6-4d2e-9dc4-93bf7ec75e7e": {"doc_hash": "ab9f16e8391cbed19de27e2cbde19c6b66d188df1dca9f78c6df2894d6269d4b", "ref_doc_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03"}, "c3a71e65-9093-4f3b-9b43-2d07eb99cd2b": {"doc_hash": "a1a4e13f6f26cc0ce735f6debe281dea8b644e3750d49ba049cab0c6690fc837", "ref_doc_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03"}, "3de7b7c3-d159-4d5a-8293-6d094f065c93": {"doc_hash": "d1e12615ebd00cc051264f07d4b4bbd03f6c38673795c8a0f0b36a3e13fe1fcb", "ref_doc_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03"}, "10de7e24-d51a-40e5-816b-8216cf308729": {"doc_hash": "06071de699089ecd77d8bf505ae43f96caa0e5766ea9f9257a0105fdfdac8855", "ref_doc_id": "44f84dcf-f7b0-4ac4-a1d4-0daeb5c8ad03"}, "e185aed7-a499-41cf-b47a-78ffc1476c38": {"doc_hash": "b67c4a2046fd32a2aa52c0bff8fd853ce02f574263c77d7594b5a4d4e9d1c5b3", "ref_doc_id": "e13766eb-e5e8-46ad-acb0-e3c44400bc7d"}, "d296e72e-6ec2-40f4-bb8c-e3cd1bcc5ad9": {"doc_hash": "f79fa22dc873b4e2109277fee100bbe813f45fe145b83f9cc7371375c7a5f510", "ref_doc_id": "e13766eb-e5e8-46ad-acb0-e3c44400bc7d"}, "080b7345-b233-4240-ab85-dec8bc6b41cf": {"doc_hash": "ae1e7e5622ce87868d500e7477ab7268c8ad835208dfd4c2858a3873a2afc16b", "ref_doc_id": "0321b819-7f1f-49ea-9981-2a22e01d46cf"}, "66e11fe4-b35e-48e2-8204-070252f6b48b": {"doc_hash": "1cf2512379cb3bebb29d1d9391fb83f4fcee61fca89ec6e8632153be6b1ba98c", "ref_doc_id": "0321b819-7f1f-49ea-9981-2a22e01d46cf"}, "237eb35e-f9dc-4368-9301-e93cfc026298": {"doc_hash": "196907fc1681fe7c727ad6ed97db8bddc25f07ce2c78770d390bb3a5ed7179b1", "ref_doc_id": "3c0b9233-573d-4df6-b237-1c4f8ef62827"}, "a8b74b4c-00ef-4e98-a93f-18efe5b57242": {"doc_hash": "2c793619bca5493f49de0ec2a7373e0be3c4a772a30fc2bb315150e1416b9383", "ref_doc_id": "3c0b9233-573d-4df6-b237-1c4f8ef62827"}, "f8a80534-d980-4eed-b78b-edf274f61f08": {"doc_hash": "3ef6d30d0fd6c8379ab25ab776aa55d01a126e796458ac29f58085fec0d8c053", "ref_doc_id": "a8cb6ac5-155d-46b8-aeac-6a4db224ec00"}, "ec43fa0e-656a-4cd9-bdc8-05b4b9825692": {"doc_hash": "177597464e6e697b1e629dfeb055d3969f289dcfe2ad7ebf13a3896317d43e2b", "ref_doc_id": "07ba6b56-0996-462c-9f05-399dffad92ac"}, "9156e38d-c2d4-4093-ba6c-58c2ed86fdd4": {"doc_hash": "f229afb4d931bac07bd4907cd9d1f477706b76b01ce1b79090fe058c2c89d27a", "ref_doc_id": "07ba6b56-0996-462c-9f05-399dffad92ac"}, "94b301be-3f3d-49ab-8f0f-784049a06381": {"doc_hash": "61bfc89b92a96b1fea8fb6c19ffcdc8906db46e2e56ef0fa66203147b6903c98", "ref_doc_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce"}, "3d545973-93b7-48c7-ad3f-8f162e3a2ee4": {"doc_hash": "685cbff107bfb4b8785229816da58ed61555835c852607f7127d16cd8c075d28", "ref_doc_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce"}, "ad454172-605f-4f9b-8773-ea3312e6f21d": {"doc_hash": "88c572b4fb2e55f2b153dab8df7b60d3bdd64279dd0a37f573d5b17d4dd6d81f", "ref_doc_id": "66c5e0d0-348a-40e6-867e-d1746d9673ce"}, "c0302f01-098c-4050-9b93-531867499d52": {"doc_hash": "21c79047c1b6ce9f21ad273a4ed813cb7ec0fb239d3927b14ac670305793f71b", "ref_doc_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28"}, "b70ae0d8-1983-4aaa-99b1-e6c8cb891c8d": {"doc_hash": "24bbbdf107c788e381abec2ff6518f2fbcd7cfd05a7f28b6419cbe2f273a9529", "ref_doc_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28"}, "07067ef5-479b-47ab-9f5a-a5180b1c5be8": {"doc_hash": "2cc6d6411b1785751f318abc9f88a11f37feaa19b4337c7426d687c0944523c2", "ref_doc_id": "ddd18cc5-dfdc-414a-92d7-6511e3cfee28"}, "ee3939d8-f788-4f1e-a812-0e74452b5c8a": {"doc_hash": "f69c812b94c7bf559c928717e69ed40304c6c9e1fc25b2bf895d22cb848ae30e", "ref_doc_id": "41509996-f13e-436a-aaaa-166140364176"}, "201ed5e8-19c9-4b48-835d-21828270b811": {"doc_hash": "357a6eae27302ab78ad767836884a8ea6507a3960c11bbff765e411bc00d85c8", "ref_doc_id": "41509996-f13e-436a-aaaa-166140364176"}}}